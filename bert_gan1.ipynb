{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert-gan1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNf/TM0f6W/v/tjmYVLC2P4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liuying-y/exam1/blob/main/bert_gan1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnGHDPbZJY89",
        "outputId": "59a7b98f-a251-4219-d4b9-450a5822323c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-models-official\n",
            "  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (2.8.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (2.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.15.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 77.7 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 1.9 MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.12.11)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.9 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 73.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.4.1)\n",
            "Collecting tf-slim>=1.1.0\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 79.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (3.2.2)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (5.4.8)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.5.12)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.5.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.21.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (7.1.2)\n",
            "Collecting tensorflow-text~=2.8.0\n",
            "  Downloading tensorflow_text-2.8.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 63.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (4.1.3)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 68.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (4.0.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.12.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.29.28)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.3.5)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 64.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.35.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.26.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.17.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (57.4.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (1.56.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2.23.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (21.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (3.17.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (4.2.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (4.63.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (6.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (2021.10.8)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (1.24.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (3.0.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2.10)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (13.0.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (0.5.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (2.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.6.3)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 60.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (3.10.0.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (0.24.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.14.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.44.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (1.8.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (3.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official) (0.1.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official) (1.4.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official) (1.3)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official) (2019.12.20)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official) (2.7.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (0.16.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (21.4.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (5.4.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (0.3.4)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (1.7.0)\n",
            "Building wheels for collected packages: py-cpuinfo, seqeval\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=a9f23ba14a5c0ea88c2ff9f41c60d2b7c765ef835dc3069f703c16ce9b68cfb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=d9913013982cb7f3732def4e8de25ae1f46f33f57a730d8a2d16531b011b39a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built py-cpuinfo seqeval\n",
            "Installing collected packages: tf-estimator-nightly, portalocker, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, opencv-python-headless, tf-models-official\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed colorama-0.4.4 opencv-python-headless-4.5.5.64 portalocker-2.4.0 py-cpuinfo-8.0.0 pyyaml-5.4.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.16.1 tensorflow-model-optimization-0.7.2 tensorflow-text-2.8.1 tf-estimator-nightly-2.8.0.dev2021122109 tf-models-official-2.8.0 tf-slim-1.1.0\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (1.21.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow_hub) (1.15.0)\n",
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.7/dist-packages (2.8.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.44.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.5.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (13.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.24.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.10.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tf-models-official\n",
        "!pip install tensorflow_hub\n",
        "!pip install tensorflow_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWE4yjcaJiK3",
        "outputId": "0a575051-f3f5-4714-9fdb-c72b1019d414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import expand_dims,zeros,ones,asarray\n",
        "from numpy.random import randn,randint\n",
        "from keras.datasets.mnist import load_data\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Reshape , Flatten, Conv2D,Conv2DTranspose\n",
        "from keras.layers import LeakyReLU, Dropout, Lambda, Activation \n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import OneClassSVM\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras import backend \n",
        "from keras.utils.np_utils import *\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os \n",
        "from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "os.chdir('/content/gdrive/My Drive')\n",
        "\n",
        "def read_data ( ):\n",
        "    # 读取训练集\n",
        "    dataset = pd.read_csv(r\"data_process/split1new_s3.csv\")\n",
        "    benign = pd.read_csv(r\"data_process/benign/benign1.csv\")\n",
        "    merge = dataset.append (benign)\n",
        "    trainX = merge.copy(deep = True)\n",
        "    #print ( merge.shape )\n",
        "    print ( trainX.shape )\n",
        "    dataset = pd.read_csv(r\"data_process/2/split2new_s3.csv\")\n",
        "    benign = pd.read_csv(r\"data_process/benign/benign2.csv\")\n",
        "    merge = dataset.append (benign)\n",
        "    trainX = trainX.append (merge )\n",
        "    #print ( merge.shape )\n",
        "    print ( trainX.shape )\n",
        "    \n",
        "    # 读取测试集\n",
        "    dataset = pd.read_csv(r\"data_process/3/split3new_s3.csv\")\n",
        "    benign = pd.read_csv(r\"data_process/benign/benign3.csv\")\n",
        "    testX = dataset.append (benign)\n",
        "    print ( testX.shape )\n",
        "   # print ( trainx.shape )\n",
        "    return trainX,testX\n",
        "\n",
        "def pre_process ( trainX,testX ):\n",
        "    \n",
        "    labelt=trainX.Label.copy()\n",
        "    arrs=labelt.values\n",
        "    d1=np.array(arrs)\n",
        "    values = array(d1)\n",
        "    #print(values)\n",
        "    # integer encode\n",
        "    label_encoder = LabelEncoder()\n",
        "    trainY = label_encoder.fit_transform(values)\n",
        "    print (',,')\n",
        "    print ( trainY.shape)\n",
        "    \n",
        "    labelt=testX.Label.copy()\n",
        "    arrs=labelt.values\n",
        "    d1=np.array(arrs)\n",
        "    values = array(d1)\n",
        "    testY = label_encoder.fit_transform(values)\n",
        "    print ( testY.shape)\n",
        "    \n",
        "    trainx=['']*trainX.shape[0]\n",
        "    '''\n",
        "    row2=trainX.iloc[[0],0:77]\n",
        "    rowp2=np.array(row2)\n",
        "    tep= ' '.join([str(x) for x in rowp2[0]])\n",
        "    print (tep)\n",
        "    '''  \n",
        "    \n",
        "    for r in range (0,trainX.shape[0]):\n",
        "        row2=trainX.iloc[[r],0:77]\n",
        "        rowp2=np.array(row2)\n",
        "        trainx[r]= ' '.join([str(x) for x in rowp2[0]])\n",
        "        \n",
        "    testx = ['']*testX.shape[0]\n",
        "    for r in range (0,testX.shape[0]):\n",
        "        row2=testX.iloc[[r],0:77]\n",
        "        rowp2=np.array(row2)\n",
        "        testx[r]= ' '.join([str(x) for x in rowp2[0]])\n",
        "        \n",
        "    trainx,testx = asarray(trainx), asarray(testx)\n",
        "    print ('....')\n",
        "    print (trainx.shape)\n",
        "    print ( testx.shape)\n",
        "    \n",
        "    trainset = (trainx,trainY)\n",
        "    testset = (testx,testY)\n",
        "    return (trainset, testset)\n",
        "\n",
        "\n",
        "def data_process2 (trainX,testX ):\n",
        "    labelt=trainX.Label.copy()\n",
        "    arrs=labelt.values\n",
        "    d1=np.array(arrs)\n",
        "    values = array(d1)\n",
        "    #print(values)\n",
        "    # integer encode\n",
        "    label_encoder = LabelEncoder()\n",
        "    trainY = label_encoder.fit_transform(values)\n",
        "    print (',,')\n",
        "    print ( trainY.shape)\n",
        "    \n",
        "    labelt=testX.Label.copy()\n",
        "    arrs=labelt.values\n",
        "    d1=np.array(arrs)\n",
        "    values = array(d1)\n",
        "    testY = label_encoder.fit_transform(values)\n",
        "    print ( testY.shape)\n",
        "    \n",
        "    trainx=['']*trainX.shape[0]\n",
        "    '''\n",
        "    row2=trainX.iloc[[0],0:77]\n",
        "    rowp2=np.array(row2)\n",
        "    tep= ' '.join([str(x) for x in rowp2[0]])\n",
        "    print (tep)\n",
        "    '''  \n",
        "    \n",
        "    for r in range (0,trainX.shape[0]):\n",
        "        row2=trainX.iloc[[r],0:77]\n",
        "        rowp2=np.array(row2)\n",
        "        trainx[r]= ' '.join([str(x) for x in rowp2[0]])\n",
        "        \n",
        "    testx = ['']*testX.shape[0]\n",
        "    for r in range (0,testX.shape[0]):\n",
        "        row2=testX.iloc[[r],0:77]\n",
        "        rowp2=np.array(row2)\n",
        "        testx[r]= ' '.join([str(x) for x in rowp2[0]])\n",
        "        \n",
        "    trainx,testx = asarray(trainx), asarray(testx)\n",
        "    print ('....')\n",
        "    print (trainx.shape)\n",
        "    print ( testx.shape)\n",
        "    x1 = pd.DataFrame(trainx) # header:原第一行的索引，index:原第一列的索引\n",
        "    x1.to_csv(r\"data/trainx.csv\",header=None,index=0)\n",
        "    t1 = pd.DataFrame(testx) # header:原第一行的索引，index:原第一列的索引\n",
        "    t1.to_csv(r\"data/testx.csv\",header=None,index=0)\n",
        "\n",
        "    x1_y = pd.DataFrame(trainY) # header:原第一行的索引，index:原第一列的索引\n",
        "    x1_y.to_csv(r\"data/trainY.csv\",header=None,index=0)\n",
        "    t1_y = pd.DataFrame(testY) # header:原第一行的索引，index:原第一列的索引\n",
        "    t1_y.to_csv(r\"data/testY.csv\",header=None,index=0)\n",
        "\n",
        "    trainset = (trainx,trainY)\n",
        "    testset = (testx,testY)\n",
        "    return (trainset, testset)\n",
        "def read_peocessed_data ( ):\n",
        "    # 读取训练集\n",
        "    x1 = pd.read_csv(r\"data/trainx.csv\",header=None)\n",
        "    t1 = pd.read_csv(r\"data/testx.csv\",header=None)\n",
        "    print (x1.shape)\n",
        "    print ( t1.shape)\n",
        "    x1_y = pd.read_csv(r\"data/trainY.csv\",header=None)\n",
        "    t1_y = pd.read_csv(r\"data/testY.csv\",header=None)\n",
        "    print (x1_y.shape)\n",
        "    print ( t1_y.shape)\n",
        "    trainX = np.array ( x1)\n",
        "    testX = np.array ( t1)\n",
        "    trainY = np.array ( x1_y)\n",
        "    testY = np.array (t1_y )\n",
        "    ytest = to_categorical(testY)\n",
        "    trainset = (trainX, trainY)\n",
        "    testset = (testX, ytest)\n",
        "\n",
        "    print (\",,,,\")\n",
        "    print ( trainX.shape )\n",
        "    print ( trainY.shape)\n",
        "    print ( testX.shape)\n",
        "    print ( testY.shape)\n",
        "    return trainset,testset\n",
        "\n",
        "\n",
        "def select_samples (dataset, n_classes=10 ):\n",
        "    \n",
        "    ratio = [50,5,8,5,3,12,3,4,5,5]\n",
        "    X, y = dataset\n",
        "    X_list, y_list = list(), list()\n",
        "  #  n_per_class = int(n_samples / n_classes)\n",
        "    for i in range(n_classes):\n",
        "        # get all images for this class\n",
        "        X_with_class = X[y == i]\n",
        "        # choose random instances\n",
        "        ix = randint(0, len(X_with_class), ratio[i])\n",
        "        # add to list\n",
        "        [X_list.append(X_with_class[j]) for j in ix]\n",
        "        [y_list.append(i) for j in ix]\n",
        "    \n",
        "    ytrain = to_categorical(asarray(y_list))\n",
        "    return asarray(X_list), ytrain\n",
        "    \n",
        "\n",
        "class SGAN:\n",
        "    def __init__(self):\n",
        "        self.width = 24\n",
        "        self.length = 32\n",
        "        self.channels = 1\n",
        "        self.shape = (self.width, self.length, self.channels)\n",
        "        self.latent_dim = 100\n",
        "        self.tfhub_handle_preprocess = 'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3'\n",
        "        #'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\n",
        "        #'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3'\n",
        "        #https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n",
        "        self.tfhub_handle_encoder = 'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\n",
        "        #'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n",
        "        \n",
        "        self.d_model = self.build_discriminator ( )\n",
        "        self.g_model = self.build_generator ( )\n",
        "        in_put1 = Input(shape=(), dtype=tf.string, name='text')\n",
        "        \n",
        "        self.d_model.trainable =  False\n",
        "        sgan_outlayer = self.d_model ([ in_put1 ,self.g_model.output] )\n",
        "        #(inputs1 , inputs2) = self.d_model.inputs\n",
        "        (output1, output2, output3) = self.d_model.outputs\n",
        "        self.sgan = Model ( inputs =[in_put1,self.g_model.input] ,outputs = sgan_outlayer)\n",
        "        self.sgan.compile ( loss='binary_crossentropy',optimizer=Adam(lr= 0.0002, beta_1=0.5))\n",
        "        \n",
        "        #from keras.utils.vis_utils import plot_model\n",
        "        #keras.utils.plot_model(model, to_file='graph.png', show_shapes=True)\n",
        "        \n",
        "        #tf.keras.utils.plot_model(self.sgan, to_file='sgan.png',show_shapes=True)\n",
        "        \n",
        "    def build_discriminator(self ):\n",
        "    \n",
        "        in_put = Input(shape=(), dtype=tf.string, name='text')\n",
        "        \n",
        "        # bert 特征提取层\n",
        "        preprocessing_layer = hub.KerasLayer(self.tfhub_handle_preprocess, name='preprocessing')\n",
        "        encoder_inputs = preprocessing_layer(in_put)\n",
        "        encoder = hub.KerasLayer(self.tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "        outputs = encoder(encoder_inputs)\n",
        "        net = outputs['pooled_output']\n",
        "        net = Dropout(0.1)(net)\n",
        "        \n",
        "        epochs = 5\n",
        "        steps_per_epoch = 512\n",
        "        num_train_steps = steps_per_epoch * epochs\n",
        "        num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "        init_lr = 3e-5\n",
        "        optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')\n",
        "       \n",
        "        # 定义 分类器 输出\n",
        "        c_out = Dense ( 10) ( net )\n",
        "        c_out = Activation('softmax' )(c_out)\n",
        "        #c_model = Model ( in_put, c_out)\n",
        "       # c_model.compile (loss='sparse_categorical_crossentropy',optimizer =optimizer,metrics= ['accuracy'] )\n",
        "        \n",
        "        \n",
        "        # 定义判别器 \n",
        "        #generator = self.build_generator ( )\n",
        "        g_input = Input ( shape = (768,))\n",
        "        layerd = Dense(1)\n",
        "        gd_out = layerd(g_input)\n",
        "        gd_out = Activation('sigmoid')(gd_out)\n",
        "        d_out = layerd ( net)\n",
        "        d_out = Activation('sigmoid')(d_out)\n",
        "        '''\n",
        "        d_model = Model ( in_put, d_out)\n",
        "        gd_model = Model ( g_input, gd_out)\n",
        "        gd_model.compile ( loss='binary_crossentropy',optimizer = Adam (lr=0.0002, beta_1 = 0.5), metrics = ['accuracy'])\n",
        "        d_model.compile ( loss='binary_crossentropy',optimizer = optimizer, metrics = ['accuracy'])\n",
        "        '''\n",
        "        #[c_out, d_out,gd_out]\n",
        "        discriminator = Model(inputs = [in_put, g_input],outputs ={'c_output':c_out, 'd_output':d_out,'gd_output':gd_out} )\n",
        "        discriminator.compile ( loss ={'c_output':'categorical_crossentropy','d_output':'binary_crossentropy','gd_output':'binary_crossentropy' },\n",
        "                               optimizer = optimizer,\n",
        "                               metrics = ['accuracy']\n",
        "                            )\n",
        "        # optimizer,optimizer,Adam (lr=0.0002, beta_1 = 0.5)\n",
        "        #print ( \"this is c_model\")\n",
        "        #c_model.summary()\n",
        "        #print ( \"this is d_model\")\n",
        "        discriminator.summary()\n",
        "        tf.keras.utils.plot_model(discriminator, to_file='discriminator.png',show_shapes=True)\n",
        "        return discriminator\n",
        "    \n",
        "    def build_generator (self ):\n",
        "        in_put = Input ( shape = (self.latent_dim,) )\n",
        "        \n",
        "        gen = Dense ( 128*6*8)(in_put)\n",
        "        gen = LeakyReLU ( alpha = 0.2 ) ( gen)\n",
        "        gen = Reshape ((6,8,128))(gen)\n",
        "        \n",
        "        gen = Conv2DTranspose ( 128, (4,4),strides=(2,2),padding = 'same')(gen )\n",
        "        gen = LeakyReLU (alpha = 0.2) ( gen )\n",
        "        gen = Conv2DTranspose ( 128,(4,4),strides=(2,2),padding = 'same') (gen)\n",
        "        gen = LeakyReLU (alpha = 0.2) (gen )\n",
        "        \n",
        "        gen = Conv2D ( 1, (7,7), activation ='tanh',padding = 'same')(gen)\n",
        "        gen = Reshape ((768,))(gen)\n",
        "        model = Model ( in_put, gen)\n",
        "        print ( \"this is g_model\")\n",
        "        model.summary()\n",
        "        return model\n",
        "    \n",
        "    def summarize_performance ( self,step, dataset, n_samples=100):\n",
        "        # prepare fake examples \n",
        "        #X ,_ = generate_fake_samples(g_model,latent_dim,n_samples)\n",
        "        # scale from [-1,1] to [0,1]\n",
        "        X , y = dataset\n",
        "        valid = np.ones((X.shape[0], 1))\n",
        "        fake = np.zeros((X.shape[0], 1))\n",
        "        noise = np.random.normal(0, 1, (X.shape[0], self.latent_dim))\n",
        "        gen_sample = self.g_model.predict(noise)\n",
        "       \n",
        "        d_losst,d_loss1,d_loss2,d_loss3,acc,d_acc1,d_acc2 = self.d_model.evaluate([X,gen_sample],{'c_output':y, 'd_output':valid,'gd_output':fake} , verbose=0)\n",
        "        print ('Classifier Accuracy : %.3f%%' % (acc * 100))\n",
        "        # save the generator model \n",
        "        filename2 = 'g_model_%04d.h5' % (step+1)\n",
        "        self.g_model.save(filename2)\n",
        "        # save the calssifier model\n",
        "        filename3 = 'd_model_%04d.h5' % (step+1)\n",
        "        self.d_model.save(filename3)\n",
        "        print ( '>saved :  ,%s  ,and %s '%( filename2, filename3))\n",
        "        \n",
        "        \n",
        "    def train (self,epochs, batch_size , sample_interval,dataset,testset):\n",
        "        \n",
        "        X_train , y_train = dataset\n",
        "        valid = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "        \n",
        "        \n",
        "        for i in range(epochs):\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            gen_sample = self.g_model.predict(noise)\n",
        "            \n",
        "            tx1,ty1 = select_samples( dataset)\n",
        "         \n",
        "            \n",
        "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "            tx2 = X_train[idx]\n",
        "            \n",
        "            d_losst,d_loss1,d_loss2,d_loss3,c_acc,d_acc1,d_acc2 = self.d_model.train_on_batch ([tx1,gen_sample],\n",
        "                                                  {'c_output':ty1, 'd_output':valid,'gd_output':fake}            )\n",
        "          \n",
        "            d_loss = 0.5 * np.add(d_loss2, d_loss3)\n",
        "            \n",
        "            tx2,ty2 = select_samples( dataset)\n",
        "            noise2 = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            g_loss = self.sgan.train_on_batch([tx2,noise2],{'c_output':ty1, 'd_output':valid,'gd_output':fake})\n",
        "            #[ty2, valid,fake]\n",
        "            print('>%d, c[%.3f,%.0f], d[%.3f,%.3f], g[%.3f]' % (i+1, d_loss1, c_acc*100, d_loss2, d_loss3, g_loss[0]))\n",
        "            \n",
        "            if (i+1) % (sample_interval * 1) == 0:\n",
        "                #sample_images(i,g_model,latent_dim,)\n",
        "                self.summarize_performance(i,testset)\n",
        " \n",
        "            \n",
        "            \n",
        "        \n",
        "#if __name__ == '__main__':\n",
        "#sgan = SGAN()\n",
        "#sgan.train(epochs=8401, batch_size=100, sample_interval=400,dataset=dataset)        \n",
        "'''   \n",
        "trainX, testX = read_data()\n",
        "trainSet , testSet  = data_process2 ( trainX, testX)'''\n",
        "trainSet , testSet = read_peocessed_data()\n",
        "#sgan.train ( epochs=8000, batch_size=100 , sample_interval=4000,dataset= trainSet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOBHuEsjJybn",
        "outputId": "9c7accf8-3bd0-47b9-8b91-f0071b0681e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(715792, 1)\n",
            "(361586, 1)\n",
            "(715792, 1)\n",
            "(361586, 1)\n",
            ",,,,\n",
            "(715792, 1)\n",
            "(715792, 1)\n",
            "(361586, 1)\n",
            "(361586, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sgan = SGAN()\n",
        "sgan.train ( epochs=2000, batch_size=100 , sample_interval=500,dataset= trainSet,testset = testSet)\n",
        "#sgan.summarize_performance(499,testSet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41WBBrTbJ72f",
        "outputId": "57488830-f011-4cd9-b562-4729be038331"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " preprocessing (KerasLayer)     {'input_type_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'sequence_output':  109482241   ['preprocessing[0][0]',          \n",
            "                                 (None, 128, 768),                'preprocessing[0][1]',          \n",
            "                                 'encoder_outputs':               'preprocessing[0][2]']          \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768),                                                       \n",
            "                                 'default': (None,                                                \n",
            "                                768)}                                                             \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 768)          0           ['BERT_encoder[0][13]']          \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 10)           7690        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            769         ['input_1[0][0]',                \n",
            "                                                                  'dropout[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 10)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1)            0           ['dense_1[1][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1)            0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,490,700\n",
            "Trainable params: 109,490,699\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n",
            "this is g_model\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6144)              620544    \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 6144)              0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 6, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 12, 16, 128)      262272    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 12, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 24, 32, 128)      262272    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 24, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 24, 32, 1)         6273      \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 768)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,151,361\n",
            "Trainable params: 1,151,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">1, c[2.316,15], d[0.414,0.697], g[1.916]\n",
            ">2, c[2.274,18], d[0.405,0.661], g[1.877]\n",
            ">3, c[2.277,14], d[0.413,0.620], g[1.822]\n",
            ">4, c[2.309,16], d[0.406,0.583], g[1.794]\n",
            ">5, c[2.273,18], d[0.392,0.541], g[1.743]\n",
            ">6, c[2.297,14], d[0.400,0.492], g[1.681]\n",
            ">7, c[2.314,15], d[0.391,0.441], g[1.654]\n",
            ">8, c[2.350,9], d[0.375,0.388], g[1.570]\n",
            ">9, c[2.274,19], d[0.379,0.331], g[1.503]\n",
            ">10, c[2.272,21], d[0.369,0.279], g[1.448]\n",
            ">11, c[2.270,19], d[0.348,0.235], g[1.379]\n",
            ">12, c[2.282,19], d[0.351,0.190], g[1.301]\n",
            ">13, c[2.201,25], d[0.335,0.157], g[1.285]\n",
            ">14, c[2.251,19], d[0.300,0.129], g[1.233]\n",
            ">15, c[2.219,25], d[0.298,0.110], g[1.216]\n",
            ">16, c[2.274,24], d[0.280,0.094], g[1.189]\n",
            ">17, c[2.213,25], d[0.271,0.082], g[1.171]\n",
            ">18, c[2.200,33], d[0.252,0.072], g[1.137]\n",
            ">19, c[2.149,25], d[0.251,0.066], g[1.118]\n",
            ">20, c[2.222,29], d[0.260,0.058], g[1.110]\n",
            ">21, c[2.195,23], d[0.245,0.053], g[1.097]\n",
            ">22, c[2.150,34], d[0.227,0.048], g[1.074]\n",
            ">23, c[2.075,43], d[0.231,0.045], g[1.069]\n",
            ">24, c[2.089,42], d[0.214,0.042], g[1.071]\n",
            ">25, c[1.989,45], d[0.206,0.040], g[1.029]\n",
            ">26, c[1.959,51], d[0.195,0.037], g[1.030]\n",
            ">27, c[1.977,51], d[0.202,0.035], g[1.020]\n",
            ">28, c[1.908,50], d[0.183,0.033], g[1.003]\n",
            ">29, c[1.925,50], d[0.181,0.031], g[0.978]\n",
            ">30, c[1.884,50], d[0.178,0.029], g[0.979]\n",
            ">31, c[1.878,50], d[0.184,0.027], g[0.964]\n",
            ">32, c[1.797,50], d[0.168,0.027], g[0.952]\n",
            ">33, c[1.749,50], d[0.157,0.025], g[0.937]\n",
            ">34, c[1.698,50], d[0.151,0.023], g[0.927]\n",
            ">35, c[1.763,50], d[0.140,0.023], g[0.916]\n",
            ">36, c[1.729,50], d[0.127,0.022], g[0.909]\n",
            ">37, c[1.732,50], d[0.113,0.020], g[0.899]\n",
            ">38, c[1.725,50], d[0.101,0.020], g[0.898]\n",
            ">39, c[1.732,50], d[0.096,0.019], g[0.892]\n",
            ">40, c[1.737,50], d[0.085,0.019], g[0.881]\n",
            ">41, c[1.724,50], d[0.080,0.018], g[0.881]\n",
            ">42, c[1.685,50], d[0.076,0.017], g[0.892]\n",
            ">43, c[1.669,49], d[0.074,0.016], g[0.886]\n",
            ">44, c[1.693,50], d[0.072,0.015], g[0.873]\n",
            ">45, c[1.603,53], d[0.062,0.015], g[0.881]\n",
            ">46, c[1.599,53], d[0.060,0.015], g[0.880]\n",
            ">47, c[1.593,52], d[0.053,0.014], g[0.868]\n",
            ">48, c[1.529,51], d[0.048,0.014], g[0.864]\n",
            ">49, c[1.548,52], d[0.044,0.013], g[0.842]\n",
            ">50, c[1.562,54], d[0.041,0.012], g[0.833]\n",
            ">51, c[1.514,53], d[0.043,0.012], g[0.820]\n",
            ">52, c[1.458,59], d[0.048,0.011], g[0.808]\n",
            ">53, c[1.488,58], d[0.039,0.011], g[0.804]\n",
            ">54, c[1.475,59], d[0.044,0.011], g[0.803]\n",
            ">55, c[1.397,57], d[0.036,0.011], g[0.808]\n",
            ">56, c[1.483,56], d[0.039,0.010], g[0.806]\n",
            ">57, c[1.411,57], d[0.033,0.010], g[0.794]\n",
            ">58, c[1.394,60], d[0.034,0.009], g[0.794]\n",
            ">59, c[1.440,57], d[0.035,0.009], g[0.791]\n",
            ">60, c[1.344,61], d[0.035,0.009], g[0.795]\n",
            ">61, c[1.428,59], d[0.028,0.009], g[0.793]\n",
            ">62, c[1.416,57], d[0.030,0.008], g[0.785]\n",
            ">63, c[1.412,61], d[0.035,0.008], g[0.786]\n",
            ">64, c[1.415,58], d[0.024,0.008], g[0.797]\n",
            ">65, c[1.364,60], d[0.025,0.008], g[0.782]\n",
            ">66, c[1.380,59], d[0.025,0.007], g[0.789]\n",
            ">67, c[1.352,59], d[0.021,0.007], g[0.787]\n",
            ">68, c[1.383,58], d[0.021,0.007], g[0.784]\n",
            ">69, c[1.349,58], d[0.024,0.007], g[0.780]\n",
            ">70, c[1.275,62], d[0.023,0.007], g[0.788]\n",
            ">71, c[1.306,58], d[0.024,0.007], g[0.808]\n",
            ">72, c[1.242,60], d[0.020,0.007], g[0.803]\n",
            ">73, c[1.229,62], d[0.021,0.006], g[0.812]\n",
            ">74, c[1.265,62], d[0.019,0.006], g[0.794]\n",
            ">75, c[1.304,60], d[0.018,0.006], g[0.777]\n",
            ">76, c[1.294,63], d[0.019,0.006], g[0.795]\n",
            ">77, c[1.327,58], d[0.020,0.006], g[0.796]\n",
            ">78, c[1.240,64], d[0.022,0.006], g[0.805]\n",
            ">79, c[1.245,59], d[0.022,0.006], g[0.817]\n",
            ">80, c[1.223,63], d[0.019,0.005], g[0.834]\n",
            ">81, c[1.251,60], d[0.021,0.006], g[0.819]\n",
            ">82, c[1.172,60], d[0.021,0.005], g[0.803]\n",
            ">83, c[1.095,63], d[0.023,0.005], g[0.787]\n",
            ">84, c[1.117,62], d[0.021,0.005], g[0.787]\n",
            ">85, c[1.193,62], d[0.021,0.005], g[0.785]\n",
            ">86, c[1.097,65], d[0.019,0.005], g[0.824]\n",
            ">87, c[1.187,62], d[0.019,0.005], g[0.841]\n",
            ">88, c[1.081,67], d[0.022,0.005], g[0.814]\n",
            ">89, c[1.018,69], d[0.022,0.005], g[0.794]\n",
            ">90, c[1.056,69], d[0.022,0.005], g[0.751]\n",
            ">91, c[1.003,70], d[0.028,0.004], g[0.763]\n",
            ">92, c[1.043,68], d[0.025,0.004], g[0.770]\n",
            ">93, c[1.025,68], d[0.022,0.004], g[0.806]\n",
            ">94, c[1.059,67], d[0.022,0.004], g[0.817]\n",
            ">95, c[0.946,75], d[0.021,0.004], g[0.808]\n",
            ">96, c[1.027,72], d[0.021,0.004], g[0.780]\n",
            ">97, c[0.990,69], d[0.020,0.004], g[0.752]\n",
            ">98, c[0.971,70], d[0.021,0.004], g[0.759]\n",
            ">99, c[0.900,69], d[0.023,0.004], g[0.791]\n",
            ">100, c[0.910,75], d[0.021,0.004], g[0.786]\n",
            ">101, c[0.940,75], d[0.020,0.004], g[0.790]\n",
            ">102, c[0.878,78], d[0.023,0.004], g[0.764]\n",
            ">103, c[0.893,71], d[0.015,0.004], g[0.762]\n",
            ">104, c[1.004,70], d[0.018,0.004], g[0.765]\n",
            ">105, c[0.847,76], d[0.017,0.004], g[0.745]\n",
            ">106, c[0.791,77], d[0.024,0.003], g[0.764]\n",
            ">107, c[0.835,81], d[0.021,0.003], g[0.792]\n",
            ">108, c[0.840,79], d[0.022,0.003], g[0.775]\n",
            ">109, c[0.880,78], d[0.023,0.003], g[0.742]\n",
            ">110, c[0.812,76], d[0.020,0.003], g[0.732]\n",
            ">111, c[0.806,77], d[0.019,0.003], g[0.730]\n",
            ">112, c[0.862,75], d[0.020,0.003], g[0.725]\n",
            ">113, c[0.792,78], d[0.021,0.003], g[0.736]\n",
            ">114, c[0.806,79], d[0.024,0.003], g[0.737]\n",
            ">115, c[0.806,76], d[0.026,0.003], g[0.736]\n",
            ">116, c[0.727,80], d[0.026,0.003], g[0.724]\n",
            ">117, c[0.790,78], d[0.022,0.003], g[0.724]\n",
            ">118, c[0.854,72], d[0.023,0.003], g[0.735]\n",
            ">119, c[0.782,79], d[0.022,0.003], g[0.751]\n",
            ">120, c[0.774,77], d[0.021,0.003], g[0.735]\n",
            ">121, c[0.723,82], d[0.020,0.003], g[0.730]\n",
            ">122, c[0.733,79], d[0.021,0.003], g[0.729]\n",
            ">123, c[0.654,83], d[0.020,0.003], g[0.751]\n",
            ">124, c[0.693,77], d[0.020,0.003], g[0.750]\n",
            ">125, c[0.650,81], d[0.022,0.003], g[0.738]\n",
            ">126, c[0.637,80], d[0.031,0.003], g[0.730]\n",
            ">127, c[0.725,77], d[0.022,0.003], g[0.721]\n",
            ">128, c[0.615,85], d[0.020,0.003], g[0.754]\n",
            ">129, c[0.671,82], d[0.019,0.003], g[0.738]\n",
            ">130, c[0.646,83], d[0.017,0.003], g[0.725]\n",
            ">131, c[0.579,85], d[0.018,0.002], g[0.705]\n",
            ">132, c[0.584,87], d[0.018,0.002], g[0.711]\n",
            ">133, c[0.564,85], d[0.022,0.003], g[0.710]\n",
            ">134, c[0.574,85], d[0.022,0.002], g[0.689]\n",
            ">135, c[0.499,87], d[0.021,0.002], g[0.677]\n",
            ">136, c[0.582,82], d[0.020,0.002], g[0.676]\n",
            ">137, c[0.570,82], d[0.020,0.002], g[0.710]\n",
            ">138, c[0.588,86], d[0.020,0.002], g[0.723]\n",
            ">139, c[0.558,85], d[0.020,0.002], g[0.727]\n",
            ">140, c[0.441,88], d[0.019,0.002], g[0.680]\n",
            ">141, c[0.531,86], d[0.018,0.002], g[0.688]\n",
            ">142, c[0.531,85], d[0.018,0.002], g[0.673]\n",
            ">143, c[0.443,92], d[0.019,0.002], g[0.684]\n",
            ">144, c[0.515,85], d[0.015,0.002], g[0.715]\n",
            ">145, c[0.468,87], d[0.016,0.002], g[0.734]\n",
            ">146, c[0.476,88], d[0.017,0.002], g[0.732]\n",
            ">147, c[0.463,88], d[0.017,0.002], g[0.710]\n",
            ">148, c[0.409,91], d[0.017,0.002], g[0.675]\n",
            ">149, c[0.527,84], d[0.021,0.002], g[0.658]\n",
            ">150, c[0.448,90], d[0.026,0.002], g[0.667]\n",
            ">151, c[0.472,87], d[0.027,0.002], g[0.697]\n",
            ">152, c[0.464,86], d[0.024,0.002], g[0.700]\n",
            ">153, c[0.457,88], d[0.023,0.002], g[0.666]\n",
            ">154, c[0.381,90], d[0.019,0.002], g[0.684]\n",
            ">155, c[0.427,90], d[0.020,0.002], g[0.676]\n",
            ">156, c[0.403,86], d[0.021,0.002], g[0.666]\n",
            ">157, c[0.363,95], d[0.019,0.002], g[0.647]\n",
            ">158, c[0.371,88], d[0.016,0.002], g[0.667]\n",
            ">159, c[0.371,87], d[0.021,0.002], g[0.685]\n",
            ">160, c[0.308,94], d[0.018,0.002], g[0.711]\n",
            ">161, c[0.350,93], d[0.016,0.002], g[0.700]\n",
            ">162, c[0.317,92], d[0.016,0.002], g[0.671]\n",
            ">163, c[0.272,91], d[0.017,0.002], g[0.661]\n",
            ">164, c[0.375,89], d[0.012,0.002], g[0.668]\n",
            ">165, c[0.307,93], d[0.016,0.002], g[0.672]\n",
            ">166, c[0.298,91], d[0.020,0.002], g[0.659]\n",
            ">167, c[0.282,90], d[0.018,0.002], g[0.676]\n",
            ">168, c[0.313,91], d[0.016,0.002], g[0.666]\n",
            ">169, c[0.261,94], d[0.016,0.002], g[0.660]\n",
            ">170, c[0.289,94], d[0.017,0.002], g[0.650]\n",
            ">171, c[0.263,95], d[0.017,0.002], g[0.637]\n",
            ">172, c[0.252,94], d[0.015,0.002], g[0.667]\n",
            ">173, c[0.264,95], d[0.014,0.002], g[0.653]\n",
            ">174, c[0.304,91], d[0.017,0.002], g[0.671]\n",
            ">175, c[0.246,93], d[0.023,0.002], g[0.697]\n",
            ">176, c[0.301,91], d[0.020,0.002], g[0.655]\n",
            ">177, c[0.211,94], d[0.019,0.002], g[0.651]\n",
            ">178, c[0.267,92], d[0.016,0.002], g[0.642]\n",
            ">179, c[0.242,92], d[0.018,0.002], g[0.623]\n",
            ">180, c[0.275,91], d[0.016,0.002], g[0.621]\n",
            ">181, c[0.221,97], d[0.014,0.002], g[0.642]\n",
            ">182, c[0.205,95], d[0.011,0.001], g[0.666]\n",
            ">183, c[0.240,97], d[0.012,0.002], g[0.653]\n",
            ">184, c[0.199,95], d[0.012,0.002], g[0.657]\n",
            ">185, c[0.171,95], d[0.014,0.002], g[0.627]\n",
            ">186, c[0.191,92], d[0.012,0.001], g[0.633]\n",
            ">187, c[0.244,93], d[0.014,0.001], g[0.628]\n",
            ">188, c[0.307,90], d[0.014,0.001], g[0.633]\n",
            ">189, c[0.207,94], d[0.014,0.001], g[0.599]\n",
            ">190, c[0.157,97], d[0.014,0.001], g[0.616]\n",
            ">191, c[0.193,94], d[0.012,0.001], g[0.632]\n",
            ">192, c[0.249,92], d[0.010,0.001], g[0.637]\n",
            ">193, c[0.297,90], d[0.011,0.001], g[0.652]\n",
            ">194, c[0.268,94], d[0.013,0.001], g[0.656]\n",
            ">195, c[0.221,94], d[0.012,0.001], g[0.652]\n",
            ">196, c[0.228,92], d[0.014,0.001], g[0.641]\n",
            ">197, c[0.182,94], d[0.008,0.001], g[0.615]\n",
            ">198, c[0.167,96], d[0.012,0.001], g[0.586]\n",
            ">199, c[0.186,93], d[0.009,0.001], g[0.584]\n",
            ">200, c[0.156,94], d[0.012,0.001], g[0.606]\n",
            ">201, c[0.116,98], d[0.012,0.001], g[0.614]\n",
            ">202, c[0.197,95], d[0.013,0.001], g[0.611]\n",
            ">203, c[0.170,96], d[0.014,0.001], g[0.627]\n",
            ">204, c[0.131,99], d[0.012,0.001], g[0.608]\n",
            ">205, c[0.127,97], d[0.011,0.001], g[0.576]\n",
            ">206, c[0.275,91], d[0.010,0.001], g[0.568]\n",
            ">207, c[0.241,89], d[0.011,0.001], g[0.578]\n",
            ">208, c[0.127,96], d[0.010,0.001], g[0.607]\n",
            ">209, c[0.154,95], d[0.011,0.001], g[0.624]\n",
            ">210, c[0.156,93], d[0.011,0.001], g[0.618]\n",
            ">211, c[0.111,98], d[0.009,0.001], g[0.603]\n",
            ">212, c[0.123,98], d[0.009,0.001], g[0.587]\n",
            ">213, c[0.190,92], d[0.008,0.001], g[0.615]\n",
            ">214, c[0.201,93], d[0.011,0.001], g[0.607]\n",
            ">215, c[0.107,97], d[0.009,0.001], g[0.614]\n",
            ">216, c[0.099,98], d[0.013,0.001], g[0.644]\n",
            ">217, c[0.078,99], d[0.012,0.001], g[0.616]\n",
            ">218, c[0.168,94], d[0.010,0.001], g[0.598]\n",
            ">219, c[0.187,93], d[0.009,0.001], g[0.591]\n",
            ">220, c[0.131,97], d[0.009,0.001], g[0.557]\n",
            ">221, c[0.112,97], d[0.008,0.001], g[0.554]\n",
            ">222, c[0.157,93], d[0.008,0.001], g[0.547]\n",
            ">223, c[0.155,94], d[0.008,0.001], g[0.573]\n",
            ">224, c[0.210,97], d[0.008,0.001], g[0.580]\n",
            ">225, c[0.092,98], d[0.006,0.001], g[0.619]\n",
            ">226, c[0.142,97], d[0.007,0.001], g[0.605]\n",
            ">227, c[0.206,93], d[0.007,0.001], g[0.605]\n",
            ">228, c[0.192,93], d[0.007,0.001], g[0.585]\n",
            ">229, c[0.062,100], d[0.007,0.001], g[0.587]\n",
            ">230, c[0.072,98], d[0.006,0.001], g[0.578]\n",
            ">231, c[0.116,96], d[0.006,0.001], g[0.594]\n",
            ">232, c[0.180,93], d[0.006,0.001], g[0.570]\n",
            ">233, c[0.073,99], d[0.007,0.001], g[0.567]\n",
            ">234, c[0.121,96], d[0.008,0.001], g[0.593]\n",
            ">235, c[0.150,97], d[0.008,0.001], g[0.570]\n",
            ">236, c[0.131,98], d[0.010,0.001], g[0.560]\n",
            ">237, c[0.159,94], d[0.010,0.001], g[0.546]\n",
            ">238, c[0.134,96], d[0.010,0.001], g[0.545]\n",
            ">239, c[0.122,96], d[0.008,0.001], g[0.544]\n",
            ">240, c[0.063,98], d[0.008,0.001], g[0.551]\n",
            ">241, c[0.105,96], d[0.007,0.001], g[0.559]\n",
            ">242, c[0.104,96], d[0.007,0.001], g[0.587]\n",
            ">243, c[0.050,99], d[0.006,0.001], g[0.581]\n",
            ">244, c[0.103,96], d[0.004,0.001], g[0.588]\n",
            ">245, c[0.094,97], d[0.004,0.001], g[0.593]\n",
            ">246, c[0.088,97], d[0.004,0.001], g[0.565]\n",
            ">247, c[0.099,98], d[0.004,0.001], g[0.566]\n",
            ">248, c[0.161,96], d[0.004,0.001], g[0.575]\n",
            ">249, c[0.094,96], d[0.004,0.001], g[0.583]\n",
            ">250, c[0.047,100], d[0.004,0.001], g[0.600]\n",
            ">251, c[0.065,98], d[0.005,0.001], g[0.581]\n",
            ">252, c[0.101,96], d[0.006,0.001], g[0.554]\n",
            ">253, c[0.136,95], d[0.006,0.001], g[0.542]\n",
            ">254, c[0.066,98], d[0.005,0.001], g[0.528]\n",
            ">255, c[0.068,96], d[0.005,0.001], g[0.548]\n",
            ">256, c[0.106,97], d[0.006,0.001], g[0.580]\n",
            ">257, c[0.067,98], d[0.006,0.001], g[0.561]\n",
            ">258, c[0.057,99], d[0.006,0.001], g[0.553]\n",
            ">259, c[0.066,98], d[0.005,0.001], g[0.547]\n",
            ">260, c[0.120,96], d[0.005,0.001], g[0.564]\n",
            ">261, c[0.085,96], d[0.004,0.001], g[0.551]\n",
            ">262, c[0.177,95], d[0.004,0.001], g[0.550]\n",
            ">263, c[0.212,92], d[0.006,0.001], g[0.532]\n",
            ">264, c[0.151,95], d[0.006,0.001], g[0.537]\n",
            ">265, c[0.084,96], d[0.006,0.001], g[0.553]\n",
            ">266, c[0.129,95], d[0.007,0.001], g[0.578]\n",
            ">267, c[0.171,92], d[0.006,0.001], g[0.546]\n",
            ">268, c[0.119,95], d[0.005,0.001], g[0.540]\n",
            ">269, c[0.073,99], d[0.004,0.001], g[0.506]\n",
            ">270, c[0.065,98], d[0.003,0.001], g[0.502]\n",
            ">271, c[0.081,95], d[0.003,0.001], g[0.542]\n",
            ">272, c[0.117,94], d[0.003,0.001], g[0.534]\n",
            ">273, c[0.065,97], d[0.003,0.001], g[0.546]\n",
            ">274, c[0.105,94], d[0.004,0.001], g[0.563]\n",
            ">275, c[0.021,100], d[0.004,0.001], g[0.570]\n",
            ">276, c[0.076,97], d[0.003,0.001], g[0.534]\n",
            ">277, c[0.100,96], d[0.004,0.001], g[0.553]\n",
            ">278, c[0.057,99], d[0.004,0.001], g[0.535]\n",
            ">279, c[0.118,98], d[0.004,0.001], g[0.539]\n",
            ">280, c[0.086,95], d[0.004,0.001], g[0.521]\n",
            ">281, c[0.069,97], d[0.004,0.001], g[0.517]\n",
            ">282, c[0.064,98], d[0.004,0.001], g[0.508]\n",
            ">283, c[0.073,97], d[0.004,0.001], g[0.516]\n",
            ">284, c[0.082,96], d[0.004,0.001], g[0.529]\n",
            ">285, c[0.091,97], d[0.004,0.001], g[0.518]\n",
            ">286, c[0.057,98], d[0.004,0.001], g[0.547]\n",
            ">287, c[0.115,95], d[0.003,0.001], g[0.497]\n",
            ">288, c[0.061,97], d[0.003,0.001], g[0.501]\n",
            ">289, c[0.056,97], d[0.003,0.001], g[0.528]\n",
            ">290, c[0.039,98], d[0.003,0.001], g[0.561]\n",
            ">291, c[0.154,97], d[0.003,0.001], g[0.578]\n",
            ">292, c[0.074,98], d[0.004,0.001], g[0.583]\n",
            ">293, c[0.052,99], d[0.004,0.001], g[0.566]\n",
            ">294, c[0.057,97], d[0.004,0.001], g[0.544]\n",
            ">295, c[0.045,99], d[0.003,0.001], g[0.523]\n",
            ">296, c[0.054,98], d[0.003,0.001], g[0.524]\n",
            ">297, c[0.058,97], d[0.003,0.001], g[0.524]\n",
            ">298, c[0.030,99], d[0.004,0.001], g[0.524]\n",
            ">299, c[0.114,96], d[0.003,0.001], g[0.533]\n",
            ">300, c[0.075,97], d[0.003,0.001], g[0.538]\n",
            ">301, c[0.118,96], d[0.004,0.001], g[0.528]\n",
            ">302, c[0.050,99], d[0.004,0.001], g[0.497]\n",
            ">303, c[0.113,96], d[0.004,0.001], g[0.483]\n",
            ">304, c[0.077,97], d[0.004,0.001], g[0.479]\n",
            ">305, c[0.143,96], d[0.003,0.001], g[0.485]\n",
            ">306, c[0.041,98], d[0.003,0.001], g[0.512]\n",
            ">307, c[0.039,98], d[0.003,0.001], g[0.517]\n",
            ">308, c[0.051,99], d[0.003,0.001], g[0.512]\n",
            ">309, c[0.085,97], d[0.002,0.001], g[0.520]\n",
            ">310, c[0.081,98], d[0.002,0.001], g[0.542]\n",
            ">311, c[0.055,99], d[0.002,0.001], g[0.556]\n",
            ">312, c[0.030,100], d[0.002,0.001], g[0.528]\n",
            ">313, c[0.063,98], d[0.002,0.001], g[0.523]\n",
            ">314, c[0.068,98], d[0.002,0.001], g[0.523]\n",
            ">315, c[0.076,97], d[0.002,0.001], g[0.515]\n",
            ">316, c[0.065,98], d[0.003,0.001], g[0.515]\n",
            ">317, c[0.032,100], d[0.002,0.001], g[0.483]\n",
            ">318, c[0.039,100], d[0.002,0.001], g[0.470]\n",
            ">319, c[0.032,99], d[0.003,0.001], g[0.477]\n",
            ">320, c[0.109,96], d[0.002,0.001], g[0.499]\n",
            ">321, c[0.069,98], d[0.002,0.001], g[0.517]\n",
            ">322, c[0.021,100], d[0.002,0.001], g[0.500]\n",
            ">323, c[0.025,100], d[0.002,0.001], g[0.501]\n",
            ">324, c[0.034,99], d[0.002,0.001], g[0.490]\n",
            ">325, c[0.126,96], d[0.002,0.001], g[0.479]\n",
            ">326, c[0.063,97], d[0.002,0.001], g[0.475]\n",
            ">327, c[0.031,99], d[0.002,0.001], g[0.468]\n",
            ">328, c[0.038,98], d[0.002,0.001], g[0.474]\n",
            ">329, c[0.132,95], d[0.002,0.001], g[0.488]\n",
            ">330, c[0.082,98], d[0.003,0.001], g[0.474]\n",
            ">331, c[0.063,99], d[0.003,0.001], g[0.486]\n",
            ">332, c[0.204,96], d[0.003,0.001], g[0.492]\n",
            ">333, c[0.049,98], d[0.003,0.001], g[0.512]\n",
            ">334, c[0.081,98], d[0.002,0.001], g[0.529]\n",
            ">335, c[0.068,97], d[0.002,0.001], g[0.544]\n",
            ">336, c[0.094,96], d[0.002,0.001], g[0.550]\n",
            ">337, c[0.080,96], d[0.002,0.001], g[0.551]\n",
            ">338, c[0.063,98], d[0.001,0.001], g[0.520]\n",
            ">339, c[0.043,99], d[0.001,0.001], g[0.531]\n",
            ">340, c[0.097,99], d[0.001,0.001], g[0.496]\n",
            ">341, c[0.048,99], d[0.001,0.001], g[0.477]\n",
            ">342, c[0.039,99], d[0.001,0.001], g[0.496]\n",
            ">343, c[0.096,95], d[0.001,0.001], g[0.511]\n",
            ">344, c[0.064,99], d[0.002,0.001], g[0.545]\n",
            ">345, c[0.076,97], d[0.002,0.001], g[0.509]\n",
            ">346, c[0.251,92], d[0.002,0.001], g[0.474]\n",
            ">347, c[0.086,98], d[0.002,0.001], g[0.503]\n",
            ">348, c[0.051,97], d[0.002,0.001], g[0.477]\n",
            ">349, c[0.030,100], d[0.002,0.001], g[0.500]\n",
            ">350, c[0.082,97], d[0.002,0.001], g[0.519]\n",
            ">351, c[0.073,99], d[0.002,0.001], g[0.514]\n",
            ">352, c[0.082,96], d[0.002,0.001], g[0.521]\n",
            ">353, c[0.108,98], d[0.002,0.001], g[0.506]\n",
            ">354, c[0.045,99], d[0.002,0.001], g[0.502]\n",
            ">355, c[0.042,99], d[0.002,0.001], g[0.472]\n",
            ">356, c[0.080,97], d[0.002,0.001], g[0.521]\n",
            ">357, c[0.086,96], d[0.002,0.001], g[0.489]\n",
            ">358, c[0.118,95], d[0.002,0.001], g[0.501]\n",
            ">359, c[0.030,98], d[0.002,0.001], g[0.495]\n",
            ">360, c[0.089,98], d[0.002,0.001], g[0.473]\n",
            ">361, c[0.169,96], d[0.002,0.001], g[0.492]\n",
            ">362, c[0.067,98], d[0.002,0.001], g[0.477]\n",
            ">363, c[0.034,100], d[0.002,0.001], g[0.481]\n",
            ">364, c[0.064,97], d[0.002,0.001], g[0.471]\n",
            ">365, c[0.129,94], d[0.002,0.001], g[0.491]\n",
            ">366, c[0.123,97], d[0.002,0.001], g[0.485]\n",
            ">367, c[0.114,97], d[0.002,0.001], g[0.501]\n",
            ">368, c[0.024,99], d[0.002,0.001], g[0.515]\n",
            ">369, c[0.103,97], d[0.002,0.001], g[0.501]\n",
            ">370, c[0.012,100], d[0.002,0.001], g[0.532]\n",
            ">371, c[0.013,100], d[0.002,0.001], g[0.516]\n",
            ">372, c[0.048,98], d[0.002,0.001], g[0.514]\n",
            ">373, c[0.069,97], d[0.002,0.001], g[0.512]\n",
            ">374, c[0.018,100], d[0.002,0.000], g[0.497]\n",
            ">375, c[0.056,98], d[0.002,0.001], g[0.499]\n",
            ">376, c[0.016,100], d[0.002,0.001], g[0.477]\n",
            ">377, c[0.041,98], d[0.001,0.000], g[0.478]\n",
            ">378, c[0.068,97], d[0.001,0.000], g[0.489]\n",
            ">379, c[0.042,97], d[0.001,0.000], g[0.487]\n",
            ">380, c[0.076,97], d[0.002,0.000], g[0.487]\n",
            ">381, c[0.048,98], d[0.001,0.001], g[0.498]\n",
            ">382, c[0.128,97], d[0.001,0.000], g[0.503]\n",
            ">383, c[0.040,99], d[0.001,0.000], g[0.492]\n",
            ">384, c[0.047,98], d[0.001,0.000], g[0.487]\n",
            ">385, c[0.078,97], d[0.001,0.000], g[0.488]\n",
            ">386, c[0.014,100], d[0.001,0.000], g[0.464]\n",
            ">387, c[0.037,98], d[0.001,0.000], g[0.472]\n",
            ">388, c[0.087,98], d[0.002,0.000], g[0.468]\n",
            ">389, c[0.099,96], d[0.002,0.000], g[0.460]\n",
            ">390, c[0.026,99], d[0.002,0.000], g[0.494]\n",
            ">391, c[0.023,100], d[0.002,0.000], g[0.474]\n",
            ">392, c[0.069,97], d[0.002,0.000], g[0.468]\n",
            ">393, c[0.071,97], d[0.003,0.000], g[0.461]\n",
            ">394, c[0.056,97], d[0.002,0.000], g[0.464]\n",
            ">395, c[0.026,98], d[0.002,0.000], g[0.472]\n",
            ">396, c[0.050,98], d[0.002,0.000], g[0.484]\n",
            ">397, c[0.031,98], d[0.001,0.000], g[0.487]\n",
            ">398, c[0.109,98], d[0.002,0.000], g[0.521]\n",
            ">399, c[0.068,99], d[0.001,0.000], g[0.519]\n",
            ">400, c[0.069,98], d[0.001,0.000], g[0.530]\n",
            ">401, c[0.135,95], d[0.002,0.000], g[0.525]\n",
            ">402, c[0.171,93], d[0.002,0.000], g[0.532]\n",
            ">403, c[0.018,99], d[0.001,0.000], g[0.528]\n",
            ">404, c[0.065,98], d[0.001,0.000], g[0.519]\n",
            ">405, c[0.085,96], d[0.001,0.000], g[0.487]\n",
            ">406, c[0.029,99], d[0.001,0.000], g[0.487]\n",
            ">407, c[0.036,99], d[0.001,0.000], g[0.479]\n",
            ">408, c[0.032,98], d[0.001,0.000], g[0.460]\n",
            ">409, c[0.204,93], d[0.001,0.000], g[0.464]\n",
            ">410, c[0.026,100], d[0.001,0.000], g[0.463]\n",
            ">411, c[0.057,98], d[0.001,0.000], g[0.474]\n",
            ">412, c[0.048,98], d[0.001,0.000], g[0.472]\n",
            ">413, c[0.186,94], d[0.001,0.000], g[0.452]\n",
            ">414, c[0.103,99], d[0.001,0.000], g[0.475]\n",
            ">415, c[0.061,96], d[0.001,0.000], g[0.487]\n",
            ">416, c[0.056,97], d[0.001,0.000], g[0.484]\n",
            ">417, c[0.061,97], d[0.001,0.000], g[0.463]\n",
            ">418, c[0.047,99], d[0.001,0.000], g[0.480]\n",
            ">419, c[0.018,100], d[0.001,0.000], g[0.494]\n",
            ">420, c[0.022,99], d[0.001,0.000], g[0.501]\n",
            ">421, c[0.029,99], d[0.001,0.000], g[0.507]\n",
            ">422, c[0.071,98], d[0.001,0.000], g[0.507]\n",
            ">423, c[0.016,100], d[0.001,0.000], g[0.516]\n",
            ">424, c[0.049,98], d[0.001,0.000], g[0.523]\n",
            ">425, c[0.061,98], d[0.001,0.000], g[0.518]\n",
            ">426, c[0.086,97], d[0.001,0.000], g[0.508]\n",
            ">427, c[0.010,100], d[0.001,0.000], g[0.514]\n",
            ">428, c[0.041,98], d[0.001,0.000], g[0.512]\n",
            ">429, c[0.192,94], d[0.001,0.000], g[0.491]\n",
            ">430, c[0.141,96], d[0.001,0.000], g[0.493]\n",
            ">431, c[0.041,99], d[0.001,0.000], g[0.465]\n",
            ">432, c[0.012,100], d[0.001,0.000], g[0.478]\n",
            ">433, c[0.027,99], d[0.001,0.000], g[0.490]\n",
            ">434, c[0.017,100], d[0.001,0.000], g[0.482]\n",
            ">435, c[0.018,100], d[0.001,0.000], g[0.462]\n",
            ">436, c[0.083,98], d[0.001,0.000], g[0.503]\n",
            ">437, c[0.048,99], d[0.001,0.000], g[0.500]\n",
            ">438, c[0.063,98], d[0.001,0.000], g[0.492]\n",
            ">439, c[0.030,99], d[0.001,0.000], g[0.489]\n",
            ">440, c[0.017,100], d[0.001,0.000], g[0.507]\n",
            ">441, c[0.069,98], d[0.001,0.000], g[0.490]\n",
            ">442, c[0.051,99], d[0.001,0.000], g[0.494]\n",
            ">443, c[0.033,99], d[0.001,0.000], g[0.493]\n",
            ">444, c[0.099,96], d[0.001,0.000], g[0.506]\n",
            ">445, c[0.069,97], d[0.001,0.000], g[0.492]\n",
            ">446, c[0.011,100], d[0.001,0.000], g[0.487]\n",
            ">447, c[0.014,100], d[0.001,0.000], g[0.489]\n",
            ">448, c[0.092,96], d[0.001,0.000], g[0.494]\n",
            ">449, c[0.065,98], d[0.001,0.000], g[0.522]\n",
            ">450, c[0.134,97], d[0.001,0.000], g[0.536]\n",
            ">451, c[0.070,98], d[0.001,0.000], g[0.532]\n",
            ">452, c[0.072,98], d[0.001,0.000], g[0.542]\n",
            ">453, c[0.069,99], d[0.001,0.000], g[0.539]\n",
            ">454, c[0.059,98], d[0.001,0.000], g[0.526]\n",
            ">455, c[0.167,95], d[0.001,0.000], g[0.538]\n",
            ">456, c[0.106,98], d[0.001,0.000], g[0.541]\n",
            ">457, c[0.084,94], d[0.001,0.000], g[0.540]\n",
            ">458, c[0.160,97], d[0.001,0.000], g[0.546]\n",
            ">459, c[0.068,98], d[0.001,0.000], g[0.560]\n",
            ">460, c[0.081,97], d[0.001,0.000], g[0.587]\n",
            ">461, c[0.035,99], d[0.001,0.000], g[0.573]\n",
            ">462, c[0.045,97], d[0.001,0.000], g[0.579]\n",
            ">463, c[0.033,100], d[0.001,0.000], g[0.543]\n",
            ">464, c[0.054,98], d[0.001,0.000], g[0.529]\n",
            ">465, c[0.119,98], d[0.001,0.000], g[0.533]\n",
            ">466, c[0.055,98], d[0.001,0.000], g[0.493]\n",
            ">467, c[0.046,99], d[0.001,0.000], g[0.498]\n",
            ">468, c[0.045,99], d[0.001,0.000], g[0.464]\n",
            ">469, c[0.047,99], d[0.001,0.000], g[0.456]\n",
            ">470, c[0.018,100], d[0.001,0.000], g[0.454]\n",
            ">471, c[0.046,98], d[0.002,0.000], g[0.449]\n",
            ">472, c[0.077,98], d[0.001,0.000], g[0.446]\n",
            ">473, c[0.015,100], d[0.001,0.000], g[0.448]\n",
            ">474, c[0.036,98], d[0.001,0.000], g[0.467]\n",
            ">475, c[0.046,98], d[0.001,0.000], g[0.456]\n",
            ">476, c[0.044,98], d[0.001,0.000], g[0.478]\n",
            ">477, c[0.059,97], d[0.001,0.000], g[0.501]\n",
            ">478, c[0.044,97], d[0.001,0.000], g[0.482]\n",
            ">479, c[0.058,97], d[0.001,0.000], g[0.461]\n",
            ">480, c[0.111,96], d[0.001,0.000], g[0.460]\n",
            ">481, c[0.028,99], d[0.001,0.000], g[0.469]\n",
            ">482, c[0.057,97], d[0.001,0.000], g[0.489]\n",
            ">483, c[0.069,97], d[0.001,0.000], g[0.467]\n",
            ">484, c[0.069,98], d[0.001,0.000], g[0.497]\n",
            ">485, c[0.052,96], d[0.001,0.000], g[0.488]\n",
            ">486, c[0.059,99], d[0.001,0.000], g[0.473]\n",
            ">487, c[0.041,99], d[0.001,0.000], g[0.489]\n",
            ">488, c[0.097,98], d[0.001,0.000], g[0.495]\n",
            ">489, c[0.065,98], d[0.001,0.000], g[0.497]\n",
            ">490, c[0.038,98], d[0.001,0.000], g[0.492]\n",
            ">491, c[0.076,96], d[0.001,0.000], g[0.505]\n",
            ">492, c[0.017,100], d[0.001,0.000], g[0.481]\n",
            ">493, c[0.077,97], d[0.001,0.000], g[0.506]\n",
            ">494, c[0.046,98], d[0.001,0.000], g[0.486]\n",
            ">495, c[0.026,100], d[0.001,0.000], g[0.474]\n",
            ">496, c[0.037,99], d[0.001,0.000], g[0.473]\n",
            ">497, c[0.073,96], d[0.001,0.000], g[0.465]\n",
            ">498, c[0.028,99], d[0.001,0.000], g[0.472]\n",
            ">499, c[0.038,98], d[0.001,0.000], g[0.498]\n",
            ">500, c[0.028,99], d[0.001,0.000], g[0.473]\n",
            "Classifier Accuracy : 98.842%\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">saved :  ,g_model_0500.h5  ,and d_model_0500.h5 \n",
            ">501, c[0.021,99], d[0.001,0.000], g[0.471]\n",
            ">502, c[0.016,100], d[0.001,0.000], g[0.472]\n",
            ">503, c[0.024,99], d[0.001,0.000], g[0.480]\n",
            ">504, c[0.068,99], d[0.001,0.000], g[0.479]\n",
            ">505, c[0.021,99], d[0.001,0.000], g[0.504]\n",
            ">506, c[0.084,98], d[0.001,0.000], g[0.490]\n",
            ">507, c[0.069,97], d[0.001,0.000], g[0.493]\n",
            ">508, c[0.058,98], d[0.001,0.000], g[0.481]\n",
            ">509, c[0.118,95], d[0.001,0.000], g[0.482]\n",
            ">510, c[0.041,98], d[0.001,0.000], g[0.458]\n",
            ">511, c[0.076,96], d[0.001,0.000], g[0.457]\n",
            ">512, c[0.060,99], d[0.001,0.000], g[0.459]\n",
            ">513, c[0.042,97], d[0.001,0.000], g[0.488]\n",
            ">514, c[0.053,99], d[0.001,0.000], g[0.501]\n",
            ">515, c[0.030,99], d[0.001,0.000], g[0.518]\n",
            ">516, c[0.229,94], d[0.001,0.000], g[0.522]\n",
            ">517, c[0.127,96], d[0.001,0.000], g[0.504]\n",
            ">518, c[0.051,97], d[0.001,0.000], g[0.482]\n",
            ">519, c[0.071,95], d[0.001,0.000], g[0.466]\n",
            ">520, c[0.036,98], d[0.001,0.000], g[0.470]\n",
            ">521, c[0.025,99], d[0.001,0.000], g[0.443]\n",
            ">522, c[0.011,100], d[0.001,0.000], g[0.450]\n",
            ">523, c[0.012,100], d[0.001,0.000], g[0.445]\n",
            ">524, c[0.056,98], d[0.001,0.000], g[0.473]\n",
            ">525, c[0.022,100], d[0.001,0.000], g[0.478]\n",
            ">526, c[0.057,99], d[0.001,0.000], g[0.472]\n",
            ">527, c[0.071,97], d[0.001,0.000], g[0.485]\n",
            ">528, c[0.010,100], d[0.001,0.000], g[0.486]\n",
            ">529, c[0.013,100], d[0.001,0.000], g[0.482]\n",
            ">530, c[0.083,98], d[0.001,0.000], g[0.460]\n",
            ">531, c[0.042,98], d[0.001,0.000], g[0.473]\n",
            ">532, c[0.043,99], d[0.001,0.000], g[0.455]\n",
            ">533, c[0.062,98], d[0.001,0.000], g[0.459]\n",
            ">534, c[0.027,99], d[0.001,0.000], g[0.439]\n",
            ">535, c[0.013,100], d[0.001,0.000], g[0.443]\n",
            ">536, c[0.029,98], d[0.001,0.000], g[0.453]\n",
            ">537, c[0.059,97], d[0.001,0.000], g[0.451]\n",
            ">538, c[0.034,98], d[0.001,0.000], g[0.448]\n",
            ">539, c[0.026,99], d[0.001,0.000], g[0.460]\n",
            ">540, c[0.124,98], d[0.001,0.000], g[0.472]\n",
            ">541, c[0.045,98], d[0.001,0.000], g[0.470]\n",
            ">542, c[0.021,99], d[0.001,0.000], g[0.463]\n",
            ">543, c[0.048,99], d[0.001,0.000], g[0.472]\n",
            ">544, c[0.014,100], d[0.001,0.000], g[0.477]\n",
            ">545, c[0.164,95], d[0.001,0.000], g[0.471]\n",
            ">546, c[0.026,99], d[0.001,0.000], g[0.500]\n",
            ">547, c[0.016,99], d[0.001,0.000], g[0.482]\n",
            ">548, c[0.052,98], d[0.001,0.000], g[0.490]\n",
            ">549, c[0.048,99], d[0.001,0.000], g[0.495]\n",
            ">550, c[0.043,99], d[0.001,0.000], g[0.473]\n",
            ">551, c[0.039,99], d[0.001,0.000], g[0.466]\n",
            ">552, c[0.024,99], d[0.001,0.000], g[0.477]\n",
            ">553, c[0.059,98], d[0.000,0.000], g[0.459]\n",
            ">554, c[0.029,100], d[0.001,0.000], g[0.493]\n",
            ">555, c[0.044,97], d[0.001,0.000], g[0.460]\n",
            ">556, c[0.012,100], d[0.000,0.000], g[0.459]\n",
            ">557, c[0.022,99], d[0.001,0.000], g[0.481]\n",
            ">558, c[0.043,99], d[0.001,0.000], g[0.466]\n",
            ">559, c[0.008,100], d[0.001,0.000], g[0.483]\n",
            ">560, c[0.088,97], d[0.001,0.000], g[0.491]\n",
            ">561, c[0.031,99], d[0.001,0.000], g[0.463]\n",
            ">562, c[0.056,98], d[0.001,0.000], g[0.467]\n",
            ">563, c[0.025,99], d[0.001,0.000], g[0.461]\n",
            ">564, c[0.065,99], d[0.001,0.000], g[0.463]\n",
            ">565, c[0.027,99], d[0.001,0.000], g[0.469]\n",
            ">566, c[0.042,98], d[0.001,0.000], g[0.457]\n",
            ">567, c[0.013,99], d[0.001,0.000], g[0.476]\n",
            ">568, c[0.016,100], d[0.001,0.000], g[0.451]\n",
            ">569, c[0.019,100], d[0.001,0.000], g[0.447]\n",
            ">570, c[0.033,98], d[0.001,0.000], g[0.455]\n",
            ">571, c[0.108,95], d[0.001,0.000], g[0.439]\n",
            ">572, c[0.084,95], d[0.001,0.000], g[0.426]\n",
            ">573, c[0.014,100], d[0.001,0.000], g[0.435]\n",
            ">574, c[0.044,98], d[0.001,0.000], g[0.439]\n",
            ">575, c[0.016,100], d[0.001,0.000], g[0.437]\n",
            ">576, c[0.061,98], d[0.001,0.000], g[0.462]\n",
            ">577, c[0.029,99], d[0.001,0.000], g[0.454]\n",
            ">578, c[0.018,99], d[0.001,0.000], g[0.449]\n",
            ">579, c[0.013,100], d[0.001,0.000], g[0.448]\n",
            ">580, c[0.052,97], d[0.001,0.000], g[0.453]\n",
            ">581, c[0.015,100], d[0.001,0.000], g[0.447]\n",
            ">582, c[0.017,100], d[0.001,0.000], g[0.453]\n",
            ">583, c[0.013,100], d[0.001,0.000], g[0.443]\n",
            ">584, c[0.019,99], d[0.001,0.000], g[0.453]\n",
            ">585, c[0.047,98], d[0.001,0.000], g[0.455]\n",
            ">586, c[0.011,100], d[0.001,0.000], g[0.459]\n",
            ">587, c[0.109,98], d[0.001,0.000], g[0.458]\n",
            ">588, c[0.073,97], d[0.001,0.000], g[0.479]\n",
            ">589, c[0.009,100], d[0.001,0.000], g[0.451]\n",
            ">590, c[0.039,99], d[0.001,0.000], g[0.449]\n",
            ">591, c[0.032,99], d[0.001,0.000], g[0.430]\n",
            ">592, c[0.044,99], d[0.001,0.000], g[0.458]\n",
            ">593, c[0.058,98], d[0.001,0.000], g[0.432]\n",
            ">594, c[0.028,99], d[0.001,0.000], g[0.424]\n",
            ">595, c[0.092,97], d[0.001,0.000], g[0.446]\n",
            ">596, c[0.049,98], d[0.001,0.000], g[0.438]\n",
            ">597, c[0.007,100], d[0.001,0.000], g[0.433]\n",
            ">598, c[0.047,98], d[0.001,0.000], g[0.455]\n",
            ">599, c[0.049,98], d[0.001,0.000], g[0.453]\n",
            ">600, c[0.034,99], d[0.001,0.000], g[0.442]\n",
            ">601, c[0.032,99], d[0.000,0.000], g[0.453]\n",
            ">602, c[0.040,98], d[0.001,0.000], g[0.454]\n",
            ">603, c[0.019,100], d[0.001,0.000], g[0.451]\n",
            ">604, c[0.020,100], d[0.001,0.000], g[0.463]\n",
            ">605, c[0.022,99], d[0.000,0.000], g[0.462]\n",
            ">606, c[0.020,100], d[0.000,0.000], g[0.458]\n",
            ">607, c[0.084,96], d[0.000,0.000], g[0.471]\n",
            ">608, c[0.059,98], d[0.001,0.000], g[0.445]\n",
            ">609, c[0.110,98], d[0.001,0.000], g[0.459]\n",
            ">610, c[0.012,100], d[0.001,0.000], g[0.438]\n",
            ">611, c[0.027,99], d[0.001,0.000], g[0.433]\n",
            ">612, c[0.077,97], d[0.001,0.000], g[0.445]\n",
            ">613, c[0.118,98], d[0.000,0.000], g[0.453]\n",
            ">614, c[0.039,98], d[0.000,0.000], g[0.443]\n",
            ">615, c[0.017,100], d[0.000,0.000], g[0.456]\n",
            ">616, c[0.039,98], d[0.000,0.000], g[0.439]\n",
            ">617, c[0.033,98], d[0.000,0.000], g[0.439]\n",
            ">618, c[0.019,99], d[0.000,0.000], g[0.451]\n",
            ">619, c[0.071,97], d[0.001,0.000], g[0.445]\n",
            ">620, c[0.034,99], d[0.000,0.000], g[0.437]\n",
            ">621, c[0.035,98], d[0.001,0.000], g[0.475]\n",
            ">622, c[0.014,100], d[0.001,0.000], g[0.466]\n",
            ">623, c[0.078,97], d[0.001,0.000], g[0.467]\n",
            ">624, c[0.071,98], d[0.001,0.000], g[0.454]\n",
            ">625, c[0.077,98], d[0.000,0.000], g[0.471]\n",
            ">626, c[0.084,96], d[0.001,0.000], g[0.462]\n",
            ">627, c[0.068,98], d[0.001,0.000], g[0.463]\n",
            ">628, c[0.012,100], d[0.000,0.000], g[0.458]\n",
            ">629, c[0.050,98], d[0.000,0.000], g[0.478]\n",
            ">630, c[0.016,100], d[0.000,0.000], g[0.485]\n",
            ">631, c[0.080,98], d[0.000,0.000], g[0.447]\n",
            ">632, c[0.032,99], d[0.000,0.000], g[0.487]\n",
            ">633, c[0.081,96], d[0.000,0.000], g[0.493]\n",
            ">634, c[0.128,97], d[0.001,0.000], g[0.461]\n",
            ">635, c[0.104,97], d[0.001,0.000], g[0.459]\n",
            ">636, c[0.013,100], d[0.001,0.000], g[0.489]\n",
            ">637, c[0.062,98], d[0.001,0.000], g[0.485]\n",
            ">638, c[0.106,96], d[0.001,0.000], g[0.447]\n",
            ">639, c[0.049,98], d[0.001,0.000], g[0.442]\n",
            ">640, c[0.032,99], d[0.001,0.000], g[0.441]\n",
            ">641, c[0.020,100], d[0.001,0.000], g[0.443]\n",
            ">642, c[0.008,100], d[0.001,0.000], g[0.435]\n",
            ">643, c[0.041,98], d[0.001,0.000], g[0.434]\n",
            ">644, c[0.033,99], d[0.001,0.000], g[0.441]\n",
            ">645, c[0.051,97], d[0.001,0.000], g[0.425]\n",
            ">646, c[0.035,98], d[0.001,0.000], g[0.431]\n",
            ">647, c[0.103,97], d[0.001,0.000], g[0.442]\n",
            ">648, c[0.027,99], d[0.001,0.000], g[0.432]\n",
            ">649, c[0.061,97], d[0.001,0.000], g[0.427]\n",
            ">650, c[0.016,100], d[0.001,0.000], g[0.441]\n",
            ">651, c[0.016,100], d[0.001,0.000], g[0.443]\n",
            ">652, c[0.023,99], d[0.001,0.000], g[0.452]\n",
            ">653, c[0.019,100], d[0.001,0.000], g[0.446]\n",
            ">654, c[0.015,99], d[0.001,0.000], g[0.441]\n",
            ">655, c[0.022,99], d[0.001,0.000], g[0.448]\n",
            ">656, c[0.013,99], d[0.001,0.000], g[0.467]\n",
            ">657, c[0.067,98], d[0.001,0.000], g[0.453]\n",
            ">658, c[0.019,100], d[0.001,0.000], g[0.458]\n",
            ">659, c[0.003,100], d[0.001,0.000], g[0.447]\n",
            ">660, c[0.006,100], d[0.001,0.000], g[0.435]\n",
            ">661, c[0.034,98], d[0.001,0.000], g[0.435]\n",
            ">662, c[0.005,100], d[0.000,0.000], g[0.443]\n",
            ">663, c[0.054,98], d[0.001,0.000], g[0.422]\n",
            ">664, c[0.117,95], d[0.001,0.000], g[0.427]\n",
            ">665, c[0.019,99], d[0.001,0.000], g[0.421]\n",
            ">666, c[0.033,98], d[0.001,0.000], g[0.432]\n",
            ">667, c[0.015,99], d[0.000,0.000], g[0.442]\n",
            ">668, c[0.011,100], d[0.001,0.000], g[0.434]\n",
            ">669, c[0.030,99], d[0.001,0.000], g[0.424]\n",
            ">670, c[0.008,100], d[0.000,0.000], g[0.441]\n",
            ">671, c[0.005,100], d[0.000,0.000], g[0.439]\n",
            ">672, c[0.022,99], d[0.001,0.000], g[0.421]\n",
            ">673, c[0.011,99], d[0.001,0.000], g[0.431]\n",
            ">674, c[0.028,98], d[0.001,0.000], g[0.420]\n",
            ">675, c[0.010,100], d[0.001,0.000], g[0.425]\n",
            ">676, c[0.038,99], d[0.001,0.000], g[0.422]\n",
            ">677, c[0.015,99], d[0.000,0.000], g[0.426]\n",
            ">678, c[0.024,99], d[0.000,0.000], g[0.413]\n",
            ">679, c[0.072,99], d[0.000,0.000], g[0.419]\n",
            ">680, c[0.004,100], d[0.000,0.000], g[0.425]\n",
            ">681, c[0.003,100], d[0.000,0.000], g[0.438]\n",
            ">682, c[0.017,98], d[0.000,0.000], g[0.439]\n",
            ">683, c[0.031,99], d[0.000,0.000], g[0.441]\n",
            ">684, c[0.051,99], d[0.000,0.000], g[0.442]\n",
            ">685, c[0.013,100], d[0.000,0.000], g[0.454]\n",
            ">686, c[0.006,100], d[0.000,0.000], g[0.433]\n",
            ">687, c[0.087,99], d[0.000,0.000], g[0.477]\n",
            ">688, c[0.058,98], d[0.000,0.000], g[0.461]\n",
            ">689, c[0.021,99], d[0.000,0.000], g[0.469]\n",
            ">690, c[0.095,97], d[0.000,0.000], g[0.467]\n",
            ">691, c[0.071,97], d[0.000,0.000], g[0.460]\n",
            ">692, c[0.007,100], d[0.000,0.000], g[0.471]\n",
            ">693, c[0.036,98], d[0.000,0.000], g[0.457]\n",
            ">694, c[0.044,99], d[0.000,0.000], g[0.473]\n",
            ">695, c[0.027,99], d[0.000,0.000], g[0.471]\n",
            ">696, c[0.023,99], d[0.000,0.000], g[0.470]\n",
            ">697, c[0.072,99], d[0.000,0.000], g[0.469]\n",
            ">698, c[0.038,98], d[0.000,0.000], g[0.472]\n",
            ">699, c[0.007,100], d[0.000,0.000], g[0.499]\n",
            ">700, c[0.064,97], d[0.000,0.000], g[0.487]\n",
            ">701, c[0.011,100], d[0.000,0.000], g[0.497]\n",
            ">702, c[0.041,98], d[0.000,0.000], g[0.487]\n",
            ">703, c[0.079,96], d[0.000,0.000], g[0.475]\n",
            ">704, c[0.015,99], d[0.000,0.000], g[0.457]\n",
            ">705, c[0.092,97], d[0.000,0.000], g[0.471]\n",
            ">706, c[0.016,100], d[0.000,0.000], g[0.477]\n",
            ">707, c[0.038,98], d[0.000,0.000], g[0.469]\n",
            ">708, c[0.065,96], d[0.000,0.000], g[0.462]\n",
            ">709, c[0.066,96], d[0.000,0.000], g[0.476]\n",
            ">710, c[0.042,97], d[0.000,0.000], g[0.465]\n",
            ">711, c[0.018,100], d[0.000,0.000], g[0.464]\n",
            ">712, c[0.064,95], d[0.000,0.000], g[0.448]\n",
            ">713, c[0.037,98], d[0.000,0.000], g[0.446]\n",
            ">714, c[0.026,98], d[0.001,0.000], g[0.463]\n",
            ">715, c[0.042,99], d[0.000,0.000], g[0.451]\n",
            ">716, c[0.030,98], d[0.001,0.000], g[0.455]\n",
            ">717, c[0.014,100], d[0.000,0.000], g[0.478]\n",
            ">718, c[0.044,98], d[0.000,0.000], g[0.450]\n",
            ">719, c[0.029,99], d[0.000,0.000], g[0.452]\n",
            ">720, c[0.119,98], d[0.001,0.000], g[0.459]\n",
            ">721, c[0.028,99], d[0.001,0.000], g[0.472]\n",
            ">722, c[0.003,100], d[0.000,0.000], g[0.445]\n",
            ">723, c[0.044,98], d[0.001,0.000], g[0.448]\n",
            ">724, c[0.035,99], d[0.000,0.000], g[0.465]\n",
            ">725, c[0.052,98], d[0.000,0.000], g[0.440]\n",
            ">726, c[0.127,96], d[0.000,0.000], g[0.459]\n",
            ">727, c[0.079,98], d[0.000,0.000], g[0.462]\n",
            ">728, c[0.035,99], d[0.000,0.000], g[0.458]\n",
            ">729, c[0.032,99], d[0.000,0.000], g[0.486]\n",
            ">730, c[0.024,99], d[0.000,0.000], g[0.484]\n",
            ">731, c[0.035,99], d[0.000,0.000], g[0.481]\n",
            ">732, c[0.009,100], d[0.000,0.000], g[0.510]\n",
            ">733, c[0.025,99], d[0.001,0.000], g[0.491]\n",
            ">734, c[0.006,100], d[0.000,0.000], g[0.524]\n",
            ">735, c[0.035,98], d[0.000,0.000], g[0.505]\n",
            ">736, c[0.006,100], d[0.000,0.000], g[0.512]\n",
            ">737, c[0.033,98], d[0.000,0.000], g[0.510]\n",
            ">738, c[0.036,98], d[0.000,0.000], g[0.509]\n",
            ">739, c[0.024,100], d[0.000,0.000], g[0.494]\n",
            ">740, c[0.041,99], d[0.000,0.000], g[0.512]\n",
            ">741, c[0.068,96], d[0.000,0.000], g[0.471]\n",
            ">742, c[0.019,100], d[0.000,0.000], g[0.471]\n",
            ">743, c[0.041,97], d[0.000,0.000], g[0.475]\n",
            ">744, c[0.012,100], d[0.000,0.000], g[0.445]\n",
            ">745, c[0.034,99], d[0.000,0.000], g[0.465]\n",
            ">746, c[0.019,100], d[0.000,0.000], g[0.459]\n",
            ">747, c[0.031,98], d[0.000,0.000], g[0.442]\n",
            ">748, c[0.015,100], d[0.000,0.000], g[0.450]\n",
            ">749, c[0.011,100], d[0.000,0.000], g[0.440]\n",
            ">750, c[0.065,98], d[0.000,0.000], g[0.433]\n",
            ">751, c[0.009,100], d[0.000,0.000], g[0.441]\n",
            ">752, c[0.051,98], d[0.001,0.000], g[0.451]\n",
            ">753, c[0.017,99], d[0.000,0.000], g[0.444]\n",
            ">754, c[0.020,99], d[0.000,0.000], g[0.462]\n",
            ">755, c[0.034,99], d[0.001,0.000], g[0.456]\n",
            ">756, c[0.063,98], d[0.001,0.000], g[0.475]\n",
            ">757, c[0.041,98], d[0.001,0.000], g[0.487]\n",
            ">758, c[0.015,100], d[0.001,0.000], g[0.477]\n",
            ">759, c[0.008,100], d[0.001,0.000], g[0.458]\n",
            ">760, c[0.073,97], d[0.001,0.000], g[0.450]\n",
            ">761, c[0.047,98], d[0.001,0.000], g[0.464]\n",
            ">762, c[0.024,99], d[0.001,0.000], g[0.452]\n",
            ">763, c[0.005,100], d[0.000,0.000], g[0.457]\n",
            ">764, c[0.031,98], d[0.000,0.000], g[0.451]\n",
            ">765, c[0.045,98], d[0.000,0.000], g[0.446]\n",
            ">766, c[0.019,99], d[0.000,0.000], g[0.457]\n",
            ">767, c[0.012,100], d[0.000,0.000], g[0.428]\n",
            ">768, c[0.003,100], d[0.000,0.000], g[0.461]\n",
            ">769, c[0.015,100], d[0.000,0.000], g[0.448]\n",
            ">770, c[0.058,99], d[0.000,0.000], g[0.446]\n",
            ">771, c[0.029,98], d[0.000,0.000], g[0.433]\n",
            ">772, c[0.013,100], d[0.000,0.000], g[0.442]\n",
            ">773, c[0.040,98], d[0.000,0.000], g[0.461]\n",
            ">774, c[0.016,100], d[0.000,0.000], g[0.450]\n",
            ">775, c[0.008,100], d[0.000,0.000], g[0.443]\n",
            ">776, c[0.010,100], d[0.000,0.000], g[0.464]\n",
            ">777, c[0.038,99], d[0.000,0.000], g[0.468]\n",
            ">778, c[0.023,99], d[0.000,0.000], g[0.456]\n",
            ">779, c[0.040,99], d[0.000,0.000], g[0.466]\n",
            ">780, c[0.017,99], d[0.000,0.000], g[0.474]\n",
            ">781, c[0.005,100], d[0.001,0.000], g[0.481]\n",
            ">782, c[0.033,99], d[0.001,0.000], g[0.470]\n",
            ">783, c[0.004,100], d[0.001,0.000], g[0.456]\n",
            ">784, c[0.106,96], d[0.001,0.000], g[0.439]\n",
            ">785, c[0.088,97], d[0.000,0.000], g[0.449]\n",
            ">786, c[0.007,100], d[0.000,0.000], g[0.458]\n",
            ">787, c[0.011,99], d[0.001,0.000], g[0.446]\n",
            ">788, c[0.047,98], d[0.000,0.000], g[0.452]\n",
            ">789, c[0.055,97], d[0.000,0.000], g[0.462]\n",
            ">790, c[0.004,100], d[0.000,0.000], g[0.456]\n",
            ">791, c[0.009,100], d[0.000,0.000], g[0.452]\n",
            ">792, c[0.002,100], d[0.000,0.000], g[0.473]\n",
            ">793, c[0.063,98], d[0.000,0.000], g[0.469]\n",
            ">794, c[0.007,100], d[0.000,0.000], g[0.454]\n",
            ">795, c[0.042,99], d[0.000,0.000], g[0.466]\n",
            ">796, c[0.010,100], d[0.000,0.000], g[0.461]\n",
            ">797, c[0.021,99], d[0.000,0.000], g[0.454]\n",
            ">798, c[0.007,100], d[0.001,0.000], g[0.449]\n",
            ">799, c[0.034,97], d[0.000,0.000], g[0.477]\n",
            ">800, c[0.035,98], d[0.000,0.000], g[0.455]\n",
            ">801, c[0.113,95], d[0.001,0.000], g[0.470]\n",
            ">802, c[0.027,99], d[0.000,0.000], g[0.447]\n",
            ">803, c[0.039,98], d[0.000,0.000], g[0.457]\n",
            ">804, c[0.019,99], d[0.000,0.000], g[0.452]\n",
            ">805, c[0.037,99], d[0.000,0.000], g[0.463]\n",
            ">806, c[0.004,100], d[0.000,0.000], g[0.472]\n",
            ">807, c[0.025,99], d[0.000,0.000], g[0.479]\n",
            ">808, c[0.027,99], d[0.000,0.000], g[0.471]\n",
            ">809, c[0.053,97], d[0.000,0.000], g[0.467]\n",
            ">810, c[0.028,98], d[0.000,0.000], g[0.471]\n",
            ">811, c[0.010,100], d[0.000,0.000], g[0.486]\n",
            ">812, c[0.021,99], d[0.000,0.000], g[0.470]\n",
            ">813, c[0.033,99], d[0.000,0.000], g[0.506]\n",
            ">814, c[0.014,99], d[0.000,0.000], g[0.460]\n",
            ">815, c[0.035,97], d[0.000,0.000], g[0.477]\n",
            ">816, c[0.003,100], d[0.000,0.000], g[0.458]\n",
            ">817, c[0.074,98], d[0.000,0.000], g[0.457]\n",
            ">818, c[0.021,99], d[0.000,0.000], g[0.470]\n",
            ">819, c[0.021,99], d[0.000,0.000], g[0.456]\n",
            ">820, c[0.058,98], d[0.000,0.000], g[0.463]\n",
            ">821, c[0.013,100], d[0.000,0.000], g[0.456]\n",
            ">822, c[0.014,100], d[0.000,0.000], g[0.459]\n",
            ">823, c[0.036,98], d[0.000,0.000], g[0.461]\n",
            ">824, c[0.013,100], d[0.000,0.000], g[0.451]\n",
            ">825, c[0.005,100], d[0.000,0.000], g[0.448]\n",
            ">826, c[0.018,99], d[0.000,0.000], g[0.442]\n",
            ">827, c[0.115,98], d[0.000,0.000], g[0.440]\n",
            ">828, c[0.043,99], d[0.000,0.000], g[0.432]\n",
            ">829, c[0.012,99], d[0.000,0.000], g[0.436]\n",
            ">830, c[0.057,98], d[0.000,0.000], g[0.457]\n",
            ">831, c[0.017,99], d[0.000,0.000], g[0.440]\n",
            ">832, c[0.010,100], d[0.000,0.000], g[0.434]\n",
            ">833, c[0.007,100], d[0.000,0.000], g[0.414]\n",
            ">834, c[0.003,100], d[0.000,0.000], g[0.417]\n",
            ">835, c[0.055,97], d[0.000,0.000], g[0.420]\n",
            ">836, c[0.058,98], d[0.000,0.000], g[0.427]\n",
            ">837, c[0.004,100], d[0.000,0.000], g[0.438]\n",
            ">838, c[0.035,99], d[0.000,0.000], g[0.420]\n",
            ">839, c[0.043,99], d[0.000,0.000], g[0.419]\n",
            ">840, c[0.035,99], d[0.000,0.000], g[0.423]\n",
            ">841, c[0.011,100], d[0.000,0.000], g[0.412]\n",
            ">842, c[0.155,96], d[0.000,0.000], g[0.420]\n",
            ">843, c[0.055,99], d[0.000,0.000], g[0.419]\n",
            ">844, c[0.009,100], d[0.000,0.000], g[0.419]\n",
            ">845, c[0.081,99], d[0.000,0.000], g[0.429]\n",
            ">846, c[0.006,100], d[0.000,0.000], g[0.440]\n",
            ">847, c[0.038,99], d[0.000,0.000], g[0.454]\n",
            ">848, c[0.047,99], d[0.000,0.000], g[0.467]\n",
            ">849, c[0.020,99], d[0.000,0.000], g[0.468]\n",
            ">850, c[0.033,99], d[0.000,0.000], g[0.479]\n",
            ">851, c[0.029,99], d[0.000,0.000], g[0.474]\n",
            ">852, c[0.031,99], d[0.000,0.000], g[0.468]\n",
            ">853, c[0.054,96], d[0.000,0.000], g[0.464]\n",
            ">854, c[0.070,96], d[0.000,0.000], g[0.470]\n",
            ">855, c[0.031,99], d[0.000,0.000], g[0.456]\n",
            ">856, c[0.045,99], d[0.000,0.000], g[0.459]\n",
            ">857, c[0.068,97], d[0.000,0.000], g[0.452]\n",
            ">858, c[0.037,99], d[0.000,0.000], g[0.456]\n",
            ">859, c[0.025,100], d[0.000,0.000], g[0.448]\n",
            ">860, c[0.055,98], d[0.000,0.000], g[0.448]\n",
            ">861, c[0.043,98], d[0.000,0.000], g[0.451]\n",
            ">862, c[0.032,98], d[0.000,0.000], g[0.454]\n",
            ">863, c[0.068,97], d[0.000,0.000], g[0.440]\n",
            ">864, c[0.030,99], d[0.000,0.000], g[0.460]\n",
            ">865, c[0.016,100], d[0.000,0.000], g[0.444]\n",
            ">866, c[0.009,100], d[0.000,0.000], g[0.467]\n",
            ">867, c[0.097,98], d[0.000,0.000], g[0.450]\n",
            ">868, c[0.025,99], d[0.000,0.000], g[0.443]\n",
            ">869, c[0.117,97], d[0.000,0.000], g[0.455]\n",
            ">870, c[0.117,96], d[0.000,0.000], g[0.475]\n",
            ">871, c[0.096,96], d[0.000,0.000], g[0.458]\n",
            ">872, c[0.057,97], d[0.000,0.000], g[0.482]\n",
            ">873, c[0.029,99], d[0.000,0.000], g[0.453]\n",
            ">874, c[0.033,99], d[0.000,0.000], g[0.470]\n",
            ">875, c[0.027,99], d[0.000,0.000], g[0.459]\n",
            ">876, c[0.037,99], d[0.000,0.000], g[0.473]\n",
            ">877, c[0.029,99], d[0.000,0.000], g[0.460]\n",
            ">878, c[0.045,97], d[0.000,0.000], g[0.442]\n",
            ">879, c[0.028,99], d[0.000,0.000], g[0.454]\n",
            ">880, c[0.028,99], d[0.000,0.000], g[0.465]\n",
            ">881, c[0.047,97], d[0.000,0.000], g[0.449]\n",
            ">882, c[0.041,98], d[0.000,0.000], g[0.444]\n",
            ">883, c[0.087,99], d[0.000,0.000], g[0.446]\n",
            ">884, c[0.026,98], d[0.000,0.000], g[0.431]\n",
            ">885, c[0.033,100], d[0.000,0.000], g[0.450]\n",
            ">886, c[0.021,99], d[0.000,0.000], g[0.456]\n",
            ">887, c[0.029,100], d[0.000,0.000], g[0.452]\n",
            ">888, c[0.024,99], d[0.000,0.000], g[0.441]\n",
            ">889, c[0.031,99], d[0.000,0.000], g[0.452]\n",
            ">890, c[0.046,97], d[0.000,0.000], g[0.458]\n",
            ">891, c[0.035,99], d[0.000,0.000], g[0.450]\n",
            ">892, c[0.060,98], d[0.000,0.000], g[0.439]\n",
            ">893, c[0.024,99], d[0.000,0.000], g[0.441]\n",
            ">894, c[0.050,98], d[0.000,0.000], g[0.492]\n",
            ">895, c[0.045,97], d[0.000,0.000], g[0.493]\n",
            ">896, c[0.027,99], d[0.000,0.000], g[0.464]\n",
            ">897, c[0.062,98], d[0.000,0.000], g[0.468]\n",
            ">898, c[0.055,98], d[0.000,0.000], g[0.472]\n",
            ">899, c[0.011,100], d[0.000,0.000], g[0.450]\n",
            ">900, c[0.050,98], d[0.000,0.000], g[0.455]\n",
            ">901, c[0.016,99], d[0.000,0.000], g[0.445]\n",
            ">902, c[0.023,99], d[0.000,0.000], g[0.450]\n",
            ">903, c[0.012,100], d[0.000,0.000], g[0.452]\n",
            ">904, c[0.050,98], d[0.000,0.000], g[0.457]\n",
            ">905, c[0.052,97], d[0.000,0.000], g[0.439]\n",
            ">906, c[0.023,99], d[0.000,0.000], g[0.460]\n",
            ">907, c[0.005,100], d[0.000,0.000], g[0.451]\n",
            ">908, c[0.021,100], d[0.000,0.000], g[0.431]\n",
            ">909, c[0.020,100], d[0.000,0.000], g[0.434]\n",
            ">910, c[0.018,100], d[0.000,0.000], g[0.457]\n",
            ">911, c[0.011,100], d[0.000,0.000], g[0.439]\n",
            ">912, c[0.030,98], d[0.000,0.000], g[0.422]\n",
            ">913, c[0.084,98], d[0.000,0.000], g[0.413]\n",
            ">914, c[0.020,99], d[0.000,0.000], g[0.430]\n",
            ">915, c[0.008,100], d[0.000,0.000], g[0.422]\n",
            ">916, c[0.016,100], d[0.000,0.000], g[0.419]\n",
            ">917, c[0.062,96], d[0.000,0.000], g[0.432]\n",
            ">918, c[0.009,100], d[0.000,0.000], g[0.417]\n",
            ">919, c[0.045,99], d[0.000,0.000], g[0.409]\n",
            ">920, c[0.003,100], d[0.000,0.000], g[0.425]\n",
            ">921, c[0.019,99], d[0.000,0.000], g[0.436]\n",
            ">922, c[0.015,99], d[0.000,0.000], g[0.426]\n",
            ">923, c[0.006,100], d[0.000,0.000], g[0.424]\n",
            ">924, c[0.005,100], d[0.000,0.000], g[0.437]\n",
            ">925, c[0.011,100], d[0.000,0.000], g[0.423]\n",
            ">926, c[0.004,100], d[0.000,0.000], g[0.421]\n",
            ">927, c[0.033,98], d[0.000,0.000], g[0.426]\n",
            ">928, c[0.003,100], d[0.000,0.000], g[0.428]\n",
            ">929, c[0.003,100], d[0.000,0.000], g[0.427]\n",
            ">930, c[0.004,100], d[0.000,0.000], g[0.439]\n",
            ">931, c[0.030,99], d[0.000,0.000], g[0.409]\n",
            ">932, c[0.054,98], d[0.000,0.000], g[0.418]\n",
            ">933, c[0.081,98], d[0.000,0.000], g[0.406]\n",
            ">934, c[0.011,99], d[0.000,0.000], g[0.408]\n",
            ">935, c[0.007,100], d[0.000,0.000], g[0.430]\n",
            ">936, c[0.006,100], d[0.000,0.000], g[0.422]\n",
            ">937, c[0.014,100], d[0.000,0.000], g[0.414]\n",
            ">938, c[0.067,99], d[0.000,0.000], g[0.425]\n",
            ">939, c[0.058,98], d[0.000,0.000], g[0.436]\n",
            ">940, c[0.065,97], d[0.001,0.000], g[0.435]\n",
            ">941, c[0.017,100], d[0.000,0.000], g[0.427]\n",
            ">942, c[0.087,98], d[0.000,0.000], g[0.433]\n",
            ">943, c[0.031,98], d[0.000,0.000], g[0.416]\n",
            ">944, c[0.111,96], d[0.000,0.000], g[0.433]\n",
            ">945, c[0.069,98], d[0.000,0.000], g[0.429]\n",
            ">946, c[0.024,99], d[0.000,0.000], g[0.453]\n",
            ">947, c[0.004,100], d[0.000,0.000], g[0.460]\n",
            ">948, c[0.006,100], d[0.000,0.000], g[0.474]\n",
            ">949, c[0.059,98], d[0.000,0.000], g[0.460]\n",
            ">950, c[0.003,100], d[0.000,0.000], g[0.463]\n",
            ">951, c[0.096,97], d[0.000,0.000], g[0.465]\n",
            ">952, c[0.116,97], d[0.000,0.000], g[0.468]\n",
            ">953, c[0.013,100], d[0.000,0.000], g[0.461]\n",
            ">954, c[0.021,99], d[0.000,0.000], g[0.454]\n",
            ">955, c[0.096,96], d[0.000,0.000], g[0.456]\n",
            ">956, c[0.009,100], d[0.000,0.000], g[0.464]\n",
            ">957, c[0.006,100], d[0.000,0.000], g[0.443]\n",
            ">958, c[0.014,99], d[0.000,0.000], g[0.455]\n",
            ">959, c[0.021,99], d[0.000,0.000], g[0.455]\n",
            ">960, c[0.031,98], d[0.000,0.000], g[0.446]\n",
            ">961, c[0.034,99], d[0.000,0.000], g[0.446]\n",
            ">962, c[0.024,99], d[0.000,0.000], g[0.449]\n",
            ">963, c[0.014,99], d[0.000,0.000], g[0.437]\n",
            ">964, c[0.004,100], d[0.000,0.000], g[0.425]\n",
            ">965, c[0.030,98], d[0.000,0.000], g[0.433]\n",
            ">966, c[0.008,100], d[0.000,0.000], g[0.441]\n",
            ">967, c[0.024,99], d[0.000,0.000], g[0.433]\n",
            ">968, c[0.033,99], d[0.000,0.000], g[0.436]\n",
            ">969, c[0.012,100], d[0.000,0.000], g[0.419]\n",
            ">970, c[0.024,99], d[0.000,0.000], g[0.435]\n",
            ">971, c[0.016,99], d[0.000,0.000], g[0.443]\n",
            ">972, c[0.006,100], d[0.000,0.000], g[0.427]\n",
            ">973, c[0.056,97], d[0.000,0.000], g[0.422]\n",
            ">974, c[0.038,98], d[0.000,0.000], g[0.430]\n",
            ">975, c[0.251,94], d[0.000,0.000], g[0.423]\n",
            ">976, c[0.089,99], d[0.000,0.000], g[0.430]\n",
            ">977, c[0.018,100], d[0.000,0.000], g[0.434]\n",
            ">978, c[0.020,99], d[0.000,0.000], g[0.446]\n",
            ">979, c[0.025,99], d[0.000,0.000], g[0.422]\n",
            ">980, c[0.054,98], d[0.000,0.000], g[0.447]\n",
            ">981, c[0.006,100], d[0.000,0.000], g[0.417]\n",
            ">982, c[0.049,98], d[0.000,0.000], g[0.431]\n",
            ">983, c[0.076,99], d[0.000,0.000], g[0.441]\n",
            ">984, c[0.038,99], d[0.000,0.000], g[0.431]\n",
            ">985, c[0.023,99], d[0.000,0.000], g[0.444]\n",
            ">986, c[0.040,99], d[0.000,0.000], g[0.472]\n",
            ">987, c[0.013,100], d[0.000,0.000], g[0.469]\n",
            ">988, c[0.080,99], d[0.000,0.000], g[0.461]\n",
            ">989, c[0.028,99], d[0.000,0.000], g[0.463]\n",
            ">990, c[0.016,100], d[0.000,0.000], g[0.461]\n",
            ">991, c[0.014,100], d[0.000,0.000], g[0.461]\n",
            ">992, c[0.004,100], d[0.000,0.000], g[0.461]\n",
            ">993, c[0.019,99], d[0.000,0.000], g[0.464]\n",
            ">994, c[0.056,99], d[0.000,0.000], g[0.448]\n",
            ">995, c[0.012,100], d[0.000,0.000], g[0.463]\n",
            ">996, c[0.008,100], d[0.000,0.000], g[0.445]\n",
            ">997, c[0.027,98], d[0.000,0.000], g[0.447]\n",
            ">998, c[0.057,97], d[0.000,0.000], g[0.451]\n",
            ">999, c[0.030,98], d[0.000,0.000], g[0.455]\n",
            ">1000, c[0.004,100], d[0.000,0.000], g[0.470]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sgan = SGAN()\n",
        "sgan.train ( epochs=1500, batch_size=100 , sample_interval=500,dataset= trainSet,testset = testSet)\n",
        "#sgan.summarize_performance(499,testSet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "96v_hS9SlVCq",
        "outputId": "d3715f5b-59d8-4e19-d2f1-b938e3c0f889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5160405429b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrainSet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#sgan.summarize_performance(499,testSet)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SGAN' is not defined"
          ]
        }
      ]
    }
  ]
}