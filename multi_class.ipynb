{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2aa359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1174778, 14)\n",
      "(1174778, 14, 2)\n",
      "(1174778, 1, 76)\n",
      "(534416, 1, 76)\n",
      "(534416, 14, 2)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_18 (LSTM)               (None, 1, 50)             25400     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 1, 50)             20200     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 14)                714       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 66,514\n",
      "Trainable params: 66,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "23496/23496 [==============================] - 195s 8ms/step - loss: 0.9830 - accuracy: 0.7664 - val_loss: 0.7323 - val_accuracy: 0.8447\n",
      "Epoch 2/500\n",
      "23496/23496 [==============================] - 194s 8ms/step - loss: 0.9437 - accuracy: 0.7664 - val_loss: 0.7288 - val_accuracy: 0.8447\n",
      "Epoch 3/500\n",
      "23496/23496 [==============================] - 193s 8ms/step - loss: 0.8557 - accuracy: 0.7835 - val_loss: 0.6026 - val_accuracy: 0.8579\n",
      "Epoch 4/500\n",
      "23496/23496 [==============================] - 185s 8ms/step - loss: 0.6366 - accuracy: 0.8302 - val_loss: 0.5092 - val_accuracy: 0.8735\n",
      "Epoch 5/500\n",
      "23496/23496 [==============================] - 189s 8ms/step - loss: 0.5515 - accuracy: 0.8506 - val_loss: 0.4476 - val_accuracy: 0.8939\n",
      "Epoch 6/500\n",
      "23496/23496 [==============================] - 190s 8ms/step - loss: 0.4761 - accuracy: 0.8767 - val_loss: 0.3785 - val_accuracy: 0.8988\n",
      "Epoch 7/500\n",
      "23496/23496 [==============================] - 194s 8ms/step - loss: 0.4140 - accuracy: 0.8888 - val_loss: 0.3374 - val_accuracy: 0.8987\n",
      "Epoch 8/500\n",
      "23496/23496 [==============================] - 197s 8ms/step - loss: 0.3730 - accuracy: 0.8931 - val_loss: 0.3115 - val_accuracy: 0.8970\n",
      "Epoch 9/500\n",
      "23496/23496 [==============================] - 181s 8ms/step - loss: 0.3454 - accuracy: 0.9037 - val_loss: 0.3222 - val_accuracy: 0.9048\n",
      "Epoch 10/500\n",
      "23496/23496 [==============================] - 182s 8ms/step - loss: 0.3258 - accuracy: 0.9070 - val_loss: 0.2724 - val_accuracy: 0.9304\n",
      "Epoch 11/500\n",
      "23496/23496 [==============================] - 193s 8ms/step - loss: 0.3109 - accuracy: 0.9115 - val_loss: 0.2633 - val_accuracy: 0.9315\n",
      "Epoch 12/500\n",
      "23496/23496 [==============================] - 193s 8ms/step - loss: 0.2993 - accuracy: 0.9143 - val_loss: 0.2567 - val_accuracy: 0.9380\n",
      "Epoch 13/500\n",
      "23496/23496 [==============================] - 193s 8ms/step - loss: 0.2888 - accuracy: 0.9173 - val_loss: 0.2526 - val_accuracy: 0.9393\n",
      "Epoch 14/500\n",
      "23496/23496 [==============================] - 194s 8ms/step - loss: 0.2790 - accuracy: 0.9196 - val_loss: 0.2443 - val_accuracy: 0.9341\n",
      "Epoch 15/500\n",
      "23496/23496 [==============================] - 193s 8ms/step - loss: 0.2712 - accuracy: 0.9210 - val_loss: 0.2407 - val_accuracy: 0.9405\n",
      "Epoch 16/500\n",
      "23496/23496 [==============================] - 195s 8ms/step - loss: 0.2659 - accuracy: 0.9221 - val_loss: 0.2358 - val_accuracy: 0.9387\n",
      "Epoch 17/500\n",
      "23496/23496 [==============================] - 197s 8ms/step - loss: 0.2620 - accuracy: 0.9227 - val_loss: 0.2517 - val_accuracy: 0.9168\n",
      "Epoch 18/500\n",
      "23496/23496 [==============================] - 194s 8ms/step - loss: 0.2581 - accuracy: 0.9239 - val_loss: 0.2313 - val_accuracy: 0.9387\n",
      "Epoch 19/500\n",
      " 1185/23496 [>.............................] - ETA: 2:45 - loss: 0.2522 - accuracy: 0.9260"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Nov  23 16:12:11 2020\n",
    "\n",
    "@author: ramya\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,\n",
    "                             f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from keras import callbacks\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "\n",
    "\n",
    "#traindata = pd.read_csv('preprocessed_train_multiclass(a)_new.csv', header=None)\n",
    "#testdata = pd.read_csv('preprocessed_test_multiclass(a)_new.csv', header=None)\n",
    "\n",
    "X = pd.read_csv(r\"E:\\学习心得\\data\\cic-ids2018\\02-03\\ptrain1\\ptrain_1.csv\", header=None)\n",
    "Y = pd.read_csv(r\"E:\\学习心得\\data\\cic-ids2018\\02-03\\ptrain1\\train_label.csv\", header=None)\n",
    "\n",
    "T = pd.read_csv(r\"E:\\学习心得\\data\\cic-ids2018\\02-03\\pva1\\pva_1.csv\", header=None)\n",
    "C = pd.read_csv(r\"E:\\学习心得\\data\\cic-ids2018\\02-03\\pva1\\pva_label.csv\", header=None)\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train1 = np.array(Y)\n",
    "y_test1 = np.array(C)\n",
    "\n",
    "y_train = to_categorical(y_train1)\n",
    "y_test = to_categorical(y_test1)\n",
    ")\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "# Add a channels dimension\n",
    "X_train = X_train[..., tf.newaxis].astype(\"float64\")\n",
    "X_test = X_test[..., tf.newaxis].astype(\"float32\")\n",
    "batch_size = 50\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train1)).shuffle(10000).batch(50)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test1)).batch(50)\n",
    "\n",
    "\n",
    "model.add(LSTM(50,input_shape=(1, 76), return_sequences= True ))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(LSTM(50,return_sequences=True)) \n",
    "model.add(Dropout(0.01))\n",
    "#model.add(LSTM(40,return_sequences=True))   \n",
    "#model.add(Dropout(0.01))\n",
    "#model.add(LSTM(40, return_sequences=True))  \n",
    "#model.add(Dropout(0.01))\n",
    "#model.add(LSTM(40, return_sequences=True)) \n",
    "#model.add(Dropout(0.01))\n",
    "#model.add(LSTM(80, return_sequences=True)) \n",
    "#model.add(Dropout(0.01))\n",
    "model.add(LSTM(50, return_sequences=False)) \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(14))# the no. of output classes\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "#model.compile(loss = 'mean_squared_error', optimizer = 'sgd', metrics = ['accuracy'])\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "\n",
    "csv_logger = CSVLogger('multiclass_Genlstm40.csv',separator=',', append=False)\n",
    "history= model.fit(X_train, y_train1, batch_size=batch_size, epochs=500, validation_data=(X_test, y_test1),callbacks=[csv_logger])\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "y_pred = model.predict_classes(X_test)\n",
    "#print(y_pred)\n",
    "np.savetxt('multiclass_Genlstm40predicted.txt',y_pred, fmt='%01d')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "expected = y_test1\n",
    "predicted = y_pred\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)\n",
    "tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"tpr:\")\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"Classification report for %s\", model)\n",
    "print(metrics.classification_report(expected,predicted))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27eb4f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1174778, 76)\n",
      "(1174778, 76)\n"
     ]
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "X = pd.read_csv(r\"E:\\学习心得\\data\\cic-ids2018\\02-03\\ptrain1\\ptrain_1.csv\", header=None)\n",
    "#df['Flow Pkts/s']= df['Flow Pkts/s'].fillna(0)  # removing NAN and INF values\n",
    "#df['Flow Byts/s']= df['Flow Byts/s'].fillna(0)\n",
    "#df['Flow Pkts/s']= df['Flow Pkts/s'].replace(np.Infinity,1)\n",
    "#df['Flow Byts/s']= df['Flow Byts/s'].replace(np.Infinity,1)\n",
    "print ( X.shape )\n",
    "for index in X.columns:\n",
    "    X[index]=X[index].fillna(0)\n",
    "    X[index]=X[index].replace(np.Infinity,1)\n",
    "\n",
    "X.to_csv(r\"E:\\学习心得\\data\\cic-ids2018\\02-03\\ptrain1\\ptrain_1.csv\", header=None,index=0)\n",
    "print (X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a62ed95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1174778, 76)\n"
     ]
    }
   ],
   "source": [
    "#import numpy as np\n",
    "for index in X.columns:\n",
    "    X[index]=X[index].fillna(0)\n",
    "    X[index]=X[index].replace(np.Infinity,1)\n",
    "\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f788f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(534416, 76)\n",
      "(534416, 76)\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv(r\"E:\\学习心得\\data\\cic-ids2018\\02-03\\pva1\\pva_1.csv\", header=None)\n",
    "print ( X.shape )\n",
    "\n",
    "for index in X.columns:\n",
    "    X[index]=X[index].fillna(0)\n",
    "    X[index]=X[index].replace(np.Infinity,1)\n",
    "\n",
    "#X.drop ( columus=[77],axis=1,inplace=True)\n",
    "X.to_csv(r\"E:\\学习心得\\data\\cic-ids2018\\02-03\\pva1\\pva_1.csv\", header=None,index=0)\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3972ce70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(534416, 76)\n"
     ]
    }
   ],
   "source": [
    "X.drop ( columns=76,axis=1,inplace=True)\n",
    "#X.to_csv(r\"E:\\学习心得\\data\\cic-ids2018\\02-03\\pva1\\pva_1.csv\", header=None,index=0)\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e32a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(r\"E:\\学习心得\\data\\cic-ids2018\\02-03\\pva1\\pva_1.csv\", header=None,index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbb8d87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
